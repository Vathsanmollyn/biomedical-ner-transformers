{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import numpy as np\n",
    "from seqeval.metrics import classification_report, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512  # BERT's max sequence length\n",
    "DATA_DIR = \"/media/smartdragon/WORK/6th Semester/22AIE315 - Natural Language Processing/Project/New_Json_Files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(filepath):\n",
    "    data = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return Dataset.from_list(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_long_sentence(tokens, tags, max_len=MAX_LEN - 2):  # -2 for [CLS] and [SEP]\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), max_len):\n",
    "        chunk_tokens = tokens[i:i+max_len]\n",
    "        chunk_tags = tags[i:i+max_len]\n",
    "        chunks.append({'tokens': chunk_tokens, 'tags': chunk_tags})\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    split_data = []\n",
    "    for example in dataset:\n",
    "        split_sentences = split_long_sentence(example['tokens'], example['tags'])\n",
    "        split_data.extend(split_sentences)\n",
    "    return Dataset.from_list(split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(example, tokenizer, label2id):\n",
    "    tokenized = tokenizer(example['tokens'], truncation=True, max_length=512, is_split_into_words=True)\n",
    "    word_ids = tokenized.word_ids()\n",
    "\n",
    "    aligned_labels = []\n",
    "    previous_word_idx = None\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            aligned_labels.append(-100)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            aligned_labels.append(label2id.get(example['tags'][word_idx], -100))\n",
    "        else:\n",
    "            aligned_labels.append(label2id.get(example['tags'][word_idx], -100))\n",
    "\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    tokenized['labels'] = aligned_labels\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p, id2label):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_labels = []\n",
    "    true_predictions = []\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        label_sequence = []\n",
    "        prediction_sequence = []\n",
    "\n",
    "        for j in range(len(labels[i])):\n",
    "            if labels[i][j] != -100:  # Exclude padding tokens\n",
    "                label_sequence.append(id2label.get(labels[i][j], \"O\"))\n",
    "                prediction_sequence.append(id2label.get(predictions[i][j], \"O\"))\n",
    "\n",
    "        true_labels.append(label_sequence)\n",
    "        true_predictions.append(prediction_sequence)\n",
    "\n",
    "    report = classification_report(true_labels, true_predictions, output_dict=True)\n",
    "    accuracy = accuracy_score(true_labels, true_predictions)\n",
    "\n",
    "    return {\n",
    "        \"f1\": report[\"micro avg\"][\"f1-score\"],\n",
    "        \"precision\": report[\"micro avg\"][\"precision\"],\n",
    "        \"recall\": report[\"micro avg\"][\"recall\"],\n",
    "        \"accuracy\": accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_batches():\n",
    "    batch_numbers = set()\n",
    "    for file in os.listdir(DATA_DIR):\n",
    "        if file.startswith(\"combined_train_\") and file.endswith(\".jsonl\"):\n",
    "            batch_num = file.split(\"_\")[-1].replace(\".jsonl\", \"\")\n",
    "            if batch_num.isdigit():\n",
    "                batch_numbers.add(int(batch_num))\n",
    "    return sorted(batch_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(batch_num):\n",
    "    dataset_prefix = f\"combined_{batch_num}\"\n",
    "\n",
    "    train_file = os.path.join(DATA_DIR, f\"combined_train_{batch_num}.jsonl\")\n",
    "    dev_file = os.path.join(DATA_DIR, f\"combined_dev_{batch_num}.jsonl\")\n",
    "    test_file = os.path.join(DATA_DIR, f\"combined_test_{batch_num}.jsonl\")\n",
    "\n",
    "    if not os.path.exists(train_file) or not os.path.exists(dev_file) or not os.path.exists(test_file):\n",
    "        print(f\"🚨 Skipping batch {batch_num}, files not found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"🚀 Processing batch {batch_num}...\")\n",
    "\n",
    "    \n",
    "    model_path = f\"/media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch{batch_num-1}\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    # Load label2id from Batch 1 to ensure consistent label space\n",
    "    with open(os.path.join(model_path, \"label2id.json\"), \"r\") as f:\n",
    "        old_label2id = json.load(f)\n",
    "    id2label = {v: k for k, v in old_label2id.items()}\n",
    "    print(f\"✅ Loaded label2id from Batch {batch_num - 1}: {old_label2id}\")\n",
    "\n",
    "    train_dataset = preprocess_dataset(load_jsonl(train_file))\n",
    "    dev_dataset = preprocess_dataset(load_jsonl(dev_file))\n",
    "    test_dataset = preprocess_dataset(load_jsonl(test_file))\n",
    "    print(f\"After splitting: Train={len(train_dataset)}, Dev={len(dev_dataset)}, Test={len(test_dataset)}\")\n",
    "\n",
    "    unique_tags = set(tag for example in train_dataset['tags'] for tag in example)\n",
    "    label2id = {tag: i for i, tag in enumerate(sorted(unique_tags))}\n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "    train_dataset = train_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer, label2id))\n",
    "    dev_dataset = dev_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer, label2id))\n",
    "    test_dataset = test_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer, label2id))\n",
    "\n",
    "    # Load the number of labels from batch 1\n",
    "    old_num_labels = len(old_label2id)  # Should match previous training setup\n",
    "    new_num_labels = len(label2id)  # Ensure this matches the new dataset\n",
    "\n",
    "    # Load the previously trained model from batch 1\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_path, num_labels=old_num_labels\n",
    "    )\n",
    "\n",
    "    # Extract the old classifier layer\n",
    "    old_classifier = model.classifier\n",
    "\n",
    "    # Create a new classifier layer with updated label count\n",
    "    new_classifier = nn.Linear(old_classifier.in_features, new_num_labels)\n",
    "\n",
    "    # Transfer weights from the old classifier to the new one (for common labels)\n",
    "    with torch.no_grad():\n",
    "        num_common_labels = min(old_num_labels, new_num_labels)\n",
    "        new_classifier.weight[:num_common_labels, :] = old_classifier.weight[:num_common_labels, :]\n",
    "        new_classifier.bias[:num_common_labels] = old_classifier.bias[:num_common_labels]\n",
    "\n",
    "    # Assign the updated classifier to the model\n",
    "    model.classifier = new_classifier\n",
    "\n",
    "    # Save updated model before continuing training\n",
    "    model.save_pretrained(\"/media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/BioBERT-updated\")\n",
    "    print(f\"✅ Model updated to support new label set while keeping batch {batch_num - 1} training.\")\n",
    "\n",
    "    model_checkpoint = f\"/media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch{batch_num}\"\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(model_checkpoint, exist_ok=True)\n",
    "    print(f\"Directory ensured: {model_checkpoint}\")\n",
    "    model_path_2 = \"/media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/BioBERT-updated\"\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_path_2, num_labels=len(label2id))\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"BioBERT-finetuned-mtl\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_dir=\"./logs\",\n",
    "        learning_rate=3e-5,\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=64,\n",
    "        num_train_epochs=2,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        push_to_hub=False,\n",
    "        save_total_limit=2,\n",
    "        gradient_accumulation_steps=8,  # This simulates batch size 4 * 4 = 16\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=dev_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=lambda p: compute_metrics(p, id2label)\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    metrics = trainer.evaluate(test_dataset)\n",
    "    print(\"Test Set Performance:\")\n",
    "    print(metrics)\n",
    "    \n",
    "    model.save_pretrained(model_checkpoint)\n",
    "    tokenizer.save_pretrained(model_checkpoint)\n",
    "\n",
    "    print(f\"✅ Model trained and saved for batch {batch_num}\")\n",
    "\n",
    "    predictions, labels, _ = trainer.predict(test_dataset)\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # Save label2id to file\n",
    "    with open(f\"{model_checkpoint}/label2id.json\", \"w\") as f:\n",
    "        json.dump(label2id, f)\n",
    "    print(\"✅ Saved new_label2id mapping.\")\n",
    "\n",
    "    # Save label2id to file\n",
    "    with open(\"label2id.json\", \"w\") as f:\n",
    "        json.dump(label2id, f)\n",
    "    print(\"✅ Saved new_label2id mapping.\")\n",
    "    print(\"✅ Saved label2id mapping to model directory.\")\n",
    "\n",
    "    # results = classification_report(labels, predictions, output_dict=True)\n",
    "    # with open(f\"{model_checkpoint}_evaluation.json\", \"w\") as f:\n",
    "    #     json.dump(results, f)\n",
    "\n",
    "    # print(f\"📊 Evaluation results saved for batch {batch_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Detected batches: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "🚀 Processing batch 2...\n",
      "✅ Loaded label2id from Batch 1: {'B-Anatomy': 0, 'I-Anatomy': 1, 'O': 2}\n",
      "After splitting: Train=153823, Dev=58785, Test=99976\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e23ac062aab4ebe88d74d8536a20a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/153823 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701d8d3431c34b9b8b26f49331b650cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/58785 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372732c59b27412a97a83009f6c6147b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/99976 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 1 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 04:57, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.176600</td>\n",
       "      <td>0.172605</td>\n",
       "      <td>0.764258</td>\n",
       "      <td>0.762046</td>\n",
       "      <td>0.766483</td>\n",
       "      <td>0.944408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.20966263115406036, 'eval_f1': 0.790495138706408, 'eval_precision': 0.8374960229080496, 'eval_recall': 0.7484893722897562, 'eval_accuracy': 0.9342969776609724, 'eval_runtime': 16.0853, 'eval_samples_per_second': 6215.351, 'eval_steps_per_second': 97.169, 'epoch': 1.995008319467554}\n",
      "✅ Model trained and saved for batch 2\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 3...\n",
      "✅ Loaded label2id from Batch 2: {'B-Anatomy': 0, 'E-Anatomy': 1, 'I-Anatomy': 2, 'O': 3, 'S-Anatomy': 4}\n",
      "After splitting: Train=355405, Dev=71042, Test=143465\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268bfa26a6ed493c915eb2dc00ade48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/355405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096583790ae84aff82dc97f9108866b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/71042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4fbd0ac0ef4f5d86f314a2d45ab927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/143465 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 2 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1388' max='1388' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1388/1388 08:24, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.243600</td>\n",
       "      <td>0.246997</td>\n",
       "      <td>0.615185</td>\n",
       "      <td>0.708498</td>\n",
       "      <td>0.543591</td>\n",
       "      <td>0.904448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.2478257417678833, 'eval_f1': 0.6257952833794204, 'eval_precision': 0.715468051200329, 'eval_recall': 0.5560971711682915, 'eval_accuracy': 0.9054865179297635, 'eval_runtime': 23.2633, 'eval_samples_per_second': 6167.014, 'eval_steps_per_second': 96.375, 'epoch': 1.9981994958588405}\n",
      "✅ Model trained and saved for batch 3\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 4...\n",
      "✅ Loaded label2id from Batch 3: {'B-GENE': 0, 'I-GENE': 1, 'O': 2}\n",
      "After splitting: Train=355405, Dev=71042, Test=143465\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcb09ac12fc4b9a802b8a023f175a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/355405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ef70219c64464b826bed1c052bb155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/71042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a863e0a243448daf1299c5c28a896b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/143465 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 3 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1388' max='1388' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1388/1388 08:28, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>0.328689</td>\n",
       "      <td>0.640655</td>\n",
       "      <td>0.761125</td>\n",
       "      <td>0.553110</td>\n",
       "      <td>0.887403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.3303717076778412, 'eval_f1': 0.6452529967115732, 'eval_precision': 0.7689623786407767, 'eval_recall': 0.5558317189955774, 'eval_accuracy': 0.8863058406860979, 'eval_runtime': 23.6322, 'eval_samples_per_second': 6070.751, 'eval_steps_per_second': 94.871, 'epoch': 1.9981994958588405}\n",
      "✅ Model trained and saved for batch 4\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 5...\n",
      "✅ Loaded label2id from Batch 4: {'B-GENE': 0, 'E-GENE': 1, 'I-GENE': 2, 'O': 3, 'S-GENE': 4}\n",
      "After splitting: Train=891948, Dev=886324, Test=766033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bdcf3846224bff987c2d0a21dfa509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/891948 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1097041b5e4ae9af6bc34397d3da00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/886324 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479dd004f2604f7bbb6d8541be1ef51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/766033 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 4 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3484' max='3484' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3484/3484 25:28, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>0.161155</td>\n",
       "      <td>0.670918</td>\n",
       "      <td>0.770898</td>\n",
       "      <td>0.593895</td>\n",
       "      <td>0.944228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.1528538167476654, 'eval_f1': 0.681120329589038, 'eval_precision': 0.7938453375779281, 'eval_recall': 0.5964282866937735, 'eval_accuracy': 0.9469068440590976, 'eval_runtime': 141.9032, 'eval_samples_per_second': 5398.278, 'eval_steps_per_second': 84.353, 'epoch': 1.9993542369232977}\n",
      "✅ Model trained and saved for batch 5\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 6...\n",
      "✅ Loaded label2id from Batch 5: {'B-Chemical': 0, 'I-Chemical': 1, 'O': 2}\n",
      "After splitting: Train=891948, Dev=886324, Test=766033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e4400fa2fb4f279c096141a46b74c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/891948 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae7d47aeb944cd9b7f15b645bdf36b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/886324 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8acc3b1a93c46b5938b3e739aec5b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/766033 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 5 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3484' max='3484' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3484/3484 24:11, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.126300</td>\n",
       "      <td>0.213384</td>\n",
       "      <td>0.738789</td>\n",
       "      <td>0.844049</td>\n",
       "      <td>0.656872</td>\n",
       "      <td>0.937243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.20661300420761108, 'eval_f1': 0.7411235240084364, 'eval_precision': 0.8556413963077943, 'eval_recall': 0.6536410952704231, 'eval_accuracy': 0.9392072536178971, 'eval_runtime': 150.2596, 'eval_samples_per_second': 5098.062, 'eval_steps_per_second': 79.662, 'epoch': 1.9993542369232977}\n",
      "✅ Model trained and saved for batch 6\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 7...\n",
      "✅ Loaded label2id from Batch 6: {'B-Chemical': 0, 'E-Chemical': 1, 'I-Chemical': 2, 'O': 3, 'S-Chemical': 4}\n",
      "After splitting: Train=118170, Dev=117453, Test=124750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7c245925324e9a9ffdbf09903249c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/118170 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30d823682d34f0ba3dd385cb1ce5d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ec3c75513444e39cfc785eb5f74c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 6 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 04:18, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.100787</td>\n",
       "      <td>0.880105</td>\n",
       "      <td>0.923149</td>\n",
       "      <td>0.840897</td>\n",
       "      <td>0.971145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.106084</td>\n",
       "      <td>0.881270</td>\n",
       "      <td>0.927243</td>\n",
       "      <td>0.839640</td>\n",
       "      <td>0.971176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.10571897029876709, 'eval_f1': 0.8676674858425046, 'eval_precision': 0.9132366171839856, 'eval_recall': 0.8264298799104417, 'eval_accuracy': 0.9708850794844379, 'eval_runtime': 19.9792, 'eval_samples_per_second': 6243.986, 'eval_steps_per_second': 97.601, 'epoch': 1.9962100703844072}\n",
      "✅ Model trained and saved for batch 7\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 8...\n",
      "✅ Loaded label2id from Batch 7: {'B-Chemical': 0, 'I-Chemical': 1, 'O': 2}\n",
      "After splitting: Train=118170, Dev=117453, Test=124750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8ec88ecd2d486a88d9c57f57be34a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/118170 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717672056fd148ad8bebd2889965e720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc44b04883b4de9bbbaba92ba62b1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 7 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 04:25, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.144749</td>\n",
       "      <td>0.901050</td>\n",
       "      <td>0.945474</td>\n",
       "      <td>0.860613</td>\n",
       "      <td>0.968304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.149506</td>\n",
       "      <td>0.897754</td>\n",
       "      <td>0.936893</td>\n",
       "      <td>0.861754</td>\n",
       "      <td>0.966536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.14484098553657532, 'eval_f1': 0.9035407182599898, 'eval_precision': 0.9451822847769723, 'eval_recall': 0.8654134974080713, 'eval_accuracy': 0.9686057031406046, 'eval_runtime': 20.1857, 'eval_samples_per_second': 6180.132, 'eval_steps_per_second': 96.603, 'epoch': 1.9962100703844072}\n",
      "✅ Model trained and saved for batch 8\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 9...\n",
      "✅ Loaded label2id from Batch 8: {'B-Chemical': 0, 'E-Chemical': 1, 'I-Chemical': 2, 'O': 3, 'S-Chemical': 4}\n",
      "After splitting: Train=118170, Dev=117453, Test=124750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98917542fc44ae998120280e8b8b2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/118170 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efe0590a5d84a618b2e713fcc4c0266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be547390f074d63b702d0f3a1eacdd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 8 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 04:22, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.153595</td>\n",
       "      <td>0.716795</td>\n",
       "      <td>0.749330</td>\n",
       "      <td>0.686969</td>\n",
       "      <td>0.948536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.158268</td>\n",
       "      <td>0.700827</td>\n",
       "      <td>0.737971</td>\n",
       "      <td>0.667242</td>\n",
       "      <td>0.946476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.1503576934337616, 'eval_f1': 0.7106342263531985, 'eval_precision': 0.7422371332714683, 'eval_recall': 0.6816125860373649, 'eval_accuracy': 0.9491135105920504, 'eval_runtime': 20.0068, 'eval_samples_per_second': 6235.39, 'eval_steps_per_second': 97.467, 'epoch': 1.9962100703844072}\n",
      "✅ Model trained and saved for batch 9\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 10...\n",
      "✅ Loaded label2id from Batch 9: {'B-Disease': 0, 'I-Disease': 1, 'O': 2}\n",
      "After splitting: Train=118170, Dev=117453, Test=124750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b786d3321fbe405d961ff7779037e59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/118170 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2b179f743b4501bc297a87cede14f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6a3ef7f70d4a4aabff232f630616c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 9 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 04:22, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.191461</td>\n",
       "      <td>0.798998</td>\n",
       "      <td>0.852864</td>\n",
       "      <td>0.751532</td>\n",
       "      <td>0.942060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.185178</td>\n",
       "      <td>0.797884</td>\n",
       "      <td>0.824453</td>\n",
       "      <td>0.772974</td>\n",
       "      <td>0.941483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.18831795454025269, 'eval_f1': 0.7977997664556573, 'eval_precision': 0.8532833760599488, 'eval_recall': 0.7490911189335796, 'eval_accuracy': 0.94497186027658, 'eval_runtime': 20.1639, 'eval_samples_per_second': 6186.786, 'eval_steps_per_second': 96.707, 'epoch': 1.9962100703844072}\n",
      "✅ Model trained and saved for batch 10\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 11...\n",
      "✅ Loaded label2id from Batch 10: {'B-Disease': 0, 'E-Disease': 1, 'I-Disease': 2, 'O': 3, 'S-Disease': 4}\n",
      "After splitting: Train=118170, Dev=117453, Test=124750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e241861f21b4406184149ef7bc5e9928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/118170 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b7bc258601413da5a767cd3eb422c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e2520118994cb09310b7e7b347f754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 10 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 04:24, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.313149</td>\n",
       "      <td>0.799268</td>\n",
       "      <td>0.818940</td>\n",
       "      <td>0.780518</td>\n",
       "      <td>0.914011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.286993</td>\n",
       "      <td>0.800184</td>\n",
       "      <td>0.831109</td>\n",
       "      <td>0.771478</td>\n",
       "      <td>0.916008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.2766253352165222, 'eval_f1': 0.7948037311108803, 'eval_precision': 0.8238947303695505, 'eval_recall': 0.7676970235196379, 'eval_accuracy': 0.9183536793128972, 'eval_runtime': 20.2293, 'eval_samples_per_second': 6166.806, 'eval_steps_per_second': 96.395, 'epoch': 1.9962100703844072}\n",
      "✅ Model trained and saved for batch 11\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 12...\n",
      "✅ Loaded label2id from Batch 11: {'B-Chemical': 0, 'B-Disease': 1, 'I-Chemical': 2, 'I-Disease': 3, 'O': 4}\n",
      "After splitting: Train=118170, Dev=117453, Test=124750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90100359cb246008e39d829a815cda0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/118170 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b588a751e645e1aefc0428478d0008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccd8f93589a4f8c8fce25219eb73861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 11 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 04:25, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.400449</td>\n",
       "      <td>0.846761</td>\n",
       "      <td>0.877104</td>\n",
       "      <td>0.818447</td>\n",
       "      <td>0.905290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.357101</td>\n",
       "      <td>0.852024</td>\n",
       "      <td>0.876485</td>\n",
       "      <td>0.828892</td>\n",
       "      <td>0.907312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.34355494379997253, 'eval_f1': 0.848222849654837, 'eval_precision': 0.8707735833356447, 'eval_recall': 0.8268106399789308, 'eval_accuracy': 0.908278600885902, 'eval_runtime': 20.8219, 'eval_samples_per_second': 5991.299, 'eval_steps_per_second': 93.652, 'epoch': 1.9962100703844072}\n",
      "✅ Model trained and saved for batch 12\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 13...\n",
      "✅ Loaded label2id from Batch 12: {'B-Chemical': 0, 'B-Disease': 1, 'E-Chemical': 2, 'E-Disease': 3, 'I-Chemical': 4, 'I-Disease': 5, 'O': 6, 'S-Chemical': 7, 'S-Disease': 8}\n",
      "After splitting: Train=227742, Dev=44185, Test=74624\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414ee3e41572445fb286ef8fad6d65d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/227742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5a6ecd424d432f8ccdb60ab9b88103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44185 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7eb5577f6e54f228fe6a1e36afc4eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/74624 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 12 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='888' max='888' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [888/888 06:03, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.204734</td>\n",
       "      <td>0.704141</td>\n",
       "      <td>0.765090</td>\n",
       "      <td>0.652186</td>\n",
       "      <td>0.926113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.179700</td>\n",
       "      <td>0.206224</td>\n",
       "      <td>0.705732</td>\n",
       "      <td>0.788829</td>\n",
       "      <td>0.638474</td>\n",
       "      <td>0.928750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.2000012993812561, 'eval_f1': 0.6980943699266398, 'eval_precision': 0.7969276511397423, 'eval_recall': 0.62107051826678, 'eval_accuracy': 0.9280095328515239, 'eval_runtime': 11.76, 'eval_samples_per_second': 6345.597, 'eval_steps_per_second': 99.15, 'epoch': 1.998033155380725}\n",
      "✅ Model trained and saved for batch 13\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 14...\n",
      "✅ Loaded label2id from Batch 13: {'B-Protein': 0, 'I-Protein': 1, 'O': 2}\n",
      "After splitting: Train=227742, Dev=44185, Test=74624\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6e4abe2385475d931f96667b193737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/227742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279a885eee794c9ca6be365288a60345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44185 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84de3a1283304a1eba8c935547251cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/74624 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 13 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='888' max='888' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [888/888 06:02, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.268861</td>\n",
       "      <td>0.715453</td>\n",
       "      <td>0.778575</td>\n",
       "      <td>0.661798</td>\n",
       "      <td>0.920620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.166900</td>\n",
       "      <td>0.258083</td>\n",
       "      <td>0.717163</td>\n",
       "      <td>0.794504</td>\n",
       "      <td>0.653543</td>\n",
       "      <td>0.922924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.25088897347450256, 'eval_f1': 0.7222404730617608, 'eval_precision': 0.8058279116649867, 'eval_recall': 0.6543641640002976, 'eval_accuracy': 0.9249675456782469, 'eval_runtime': 11.821, 'eval_samples_per_second': 6312.833, 'eval_steps_per_second': 98.638, 'epoch': 1.998033155380725}\n",
      "✅ Model trained and saved for batch 14\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 15...\n",
      "✅ Loaded label2id from Batch 14: {'B-Protein': 0, 'E-Protein': 1, 'I-Protein': 2, 'O': 3, 'S-Protein': 4}\n",
      "After splitting: Train=161576, Dev=54760, Test=116105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb1bc2d4544449b816aea374702d240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/161576 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e353d47c9e41198a3753795af3aa28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/54760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0840a99f58574310b5390e67360246eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/116105 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 14 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [630/630 04:43, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>0.193179</td>\n",
       "      <td>0.727205</td>\n",
       "      <td>0.815716</td>\n",
       "      <td>0.656022</td>\n",
       "      <td>0.940038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.21118026971817017, 'eval_f1': 0.7038694245110454, 'eval_precision': 0.807359586830213, 'eval_recall': 0.6238962334746819, 'eval_accuracy': 0.9324187708656604, 'eval_runtime': 19.4892, 'eval_samples_per_second': 5957.417, 'eval_steps_per_second': 93.129, 'epoch': 1.9948514851485148}\n",
      "✅ Model trained and saved for batch 15\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 16...\n",
      "✅ Loaded label2id from Batch 15: {'B-Protein': 0, 'I-Protein': 1, 'O': 2}\n",
      "After splitting: Train=161576, Dev=54760, Test=116105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c68b4b13dec4d7693405ed314ce7794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/161576 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d6c0ef657345babd93dfb100a95491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/54760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15428ae799e74dac901b60145f112879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/116105 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 15 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [630/630 05:00, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.267814</td>\n",
       "      <td>0.735359</td>\n",
       "      <td>0.808396</td>\n",
       "      <td>0.674426</td>\n",
       "      <td>0.932239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.30205225944519043, 'eval_f1': 0.7202415332108165, 'eval_precision': 0.8160023795359905, 'eval_recall': 0.6445958646616541, 'eval_accuracy': 0.9252539145154465, 'eval_runtime': 19.8134, 'eval_samples_per_second': 5859.914, 'eval_steps_per_second': 91.605, 'epoch': 1.9948514851485148}\n",
      "✅ Model trained and saved for batch 16\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 17...\n",
      "✅ Loaded label2id from Batch 16: {'B-Protein': 0, 'E-Protein': 1, 'I-Protein': 2, 'O': 3, 'S-Protein': 4}\n",
      "After splitting: Train=81856, Dev=22917, Test=61643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf313b620744b438cb6bdcdf9e24945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573c29891c3349619837a97e97cc1133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26520f718774857b5309c366a2730d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 16 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 03:08, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.026199</td>\n",
       "      <td>0.718644</td>\n",
       "      <td>0.672304</td>\n",
       "      <td>0.771845</td>\n",
       "      <td>0.991367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.03281928971409798, 'eval_f1': 0.4505716207128447, 'eval_precision': 0.48833819241982507, 'eval_recall': 0.418227215980025, 'eval_accuracy': 0.9889610070315189, 'eval_runtime': 9.5133, 'eval_samples_per_second': 6479.637, 'eval_steps_per_second': 101.331, 'epoch': 1.9882720875684128}\n",
      "✅ Model trained and saved for batch 17\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 18...\n",
      "✅ Loaded label2id from Batch 17: {'B-Chemical': 0, 'I-Chemical': 1, 'O': 2}\n",
      "After splitting: Train=81856, Dev=22917, Test=61643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268a2ae3fb5f4fe48f8da4f7f20addc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daee9e4445fb4db5a52b84a4aebe74a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0115f6ecb2a44c3bc48633af73704dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 17 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 03:11, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.035827</td>\n",
       "      <td>0.735912</td>\n",
       "      <td>0.686598</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>0.991730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.03882693871855736, 'eval_f1': 0.5609123898392949, 'eval_precision': 0.52321083172147, 'eval_recall': 0.6044692737430167, 'eval_accuracy': 0.9888380783793087, 'eval_runtime': 9.5226, 'eval_samples_per_second': 6473.336, 'eval_steps_per_second': 101.233, 'epoch': 1.9882720875684128}\n",
      "✅ Model trained and saved for batch 18\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 19...\n",
      "✅ Loaded label2id from Batch 18: {'B-Chemical': 0, 'E-Chemical': 1, 'I-Chemical': 2, 'O': 3, 'S-Chemical': 4}\n",
      "After splitting: Train=81856, Dev=22917, Test=61643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09353ff7b383494e9bca1bd19226d320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51cf11f59b544b51b1b77d1cafe5559c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce9d3f3a5834eec907678d723f77955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 18 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 03:16, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.140110</td>\n",
       "      <td>0.710589</td>\n",
       "      <td>0.727939</td>\n",
       "      <td>0.694047</td>\n",
       "      <td>0.942996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.11624313145875931, 'eval_f1': 0.8125822767269452, 'eval_precision': 0.7898706896551724, 'eval_recall': 0.8366386075046369, 'eval_accuracy': 0.9659856419334218, 'eval_runtime': 9.6263, 'eval_samples_per_second': 6403.604, 'eval_steps_per_second': 100.142, 'epoch': 1.9882720875684128}\n",
      "✅ Model trained and saved for batch 19\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 20...\n",
      "✅ Loaded label2id from Batch 19: {'B-Protein': 0, 'I-Protein': 1, 'O': 2}\n",
      "After splitting: Train=81856, Dev=22917, Test=61643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c6c9c3f79c4160a23d812d782cf5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c61ab8255241d1b93c442ab8dc8bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f22424c5614d998b4a3d4efa9472c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 19 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_20214/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 03:10, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.163144</td>\n",
       "      <td>0.720217</td>\n",
       "      <td>0.740934</td>\n",
       "      <td>0.700626</td>\n",
       "      <td>0.945105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.163540318608284, 'eval_f1': 0.8083643253105046, 'eval_precision': 0.8118393234672304, 'eval_recall': 0.8049189491335942, 'eval_accuracy': 0.9633795545065644, 'eval_runtime': 10.0069, 'eval_samples_per_second': 6160.062, 'eval_steps_per_second': 96.334, 'epoch': 1.9882720875684128}\n",
      "✅ Model trained and saved for batch 20\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🎉 All detected batches processed successfully!\n"
     ]
    }
   ],
   "source": [
    "batch_numbers = detect_batches()\n",
    "print(f\"📝 Detected batches: {batch_numbers}\")\n",
    "\n",
    "for batch_num in batch_numbers:\n",
    "    train_and_evaluate(batch_num)\n",
    "\n",
    "print(\"🎉 All detected batches processed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
