{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import numpy as np\n",
    "from seqeval.metrics import classification_report, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512  # BERT's max sequence length\n",
    "DATA_DIR = \"/media/smartdragon/WORK/6th Semester/22AIE315 - Natural Language Processing/Project/New_Json_Files/Batch 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(filepath):\n",
    "    data = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return Dataset.from_list(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_long_sentence(tokens, tags, max_len=MAX_LEN - 2):  # -2 for [CLS] and [SEP]\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), max_len):\n",
    "        chunk_tokens = tokens[i:i+max_len]\n",
    "        chunk_tags = tags[i:i+max_len]\n",
    "        chunks.append({'tokens': chunk_tokens, 'tags': chunk_tags})\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    split_data = []\n",
    "    for example in dataset:\n",
    "        split_sentences = split_long_sentence(example['tokens'], example['tags'])\n",
    "        split_data.extend(split_sentences)\n",
    "    return Dataset.from_list(split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(example, tokenizer, label2id):\n",
    "    tokenized = tokenizer(example['tokens'], truncation=True, max_length=512, is_split_into_words=True)\n",
    "    word_ids = tokenized.word_ids()\n",
    "\n",
    "    aligned_labels = []\n",
    "    previous_word_idx = None\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            aligned_labels.append(-100)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            aligned_labels.append(label2id.get(example['tags'][word_idx], -100))\n",
    "        else:\n",
    "            aligned_labels.append(label2id.get(example['tags'][word_idx], -100))\n",
    "\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    tokenized['labels'] = aligned_labels\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p, id2label):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_labels = []\n",
    "    true_predictions = []\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        label_sequence = []\n",
    "        prediction_sequence = []\n",
    "\n",
    "        for j in range(len(labels[i])):\n",
    "            if labels[i][j] != -100:  # Exclude padding tokens\n",
    "                label_sequence.append(id2label.get(labels[i][j], \"O\"))\n",
    "                prediction_sequence.append(id2label.get(predictions[i][j], \"O\"))\n",
    "\n",
    "        true_labels.append(label_sequence)\n",
    "        true_predictions.append(prediction_sequence)\n",
    "\n",
    "    report = classification_report(true_labels, true_predictions, output_dict=True)\n",
    "    accuracy = accuracy_score(true_labels, true_predictions)\n",
    "\n",
    "    return {\n",
    "        \"f1\": report[\"micro avg\"][\"f1-score\"],\n",
    "        \"precision\": report[\"micro avg\"][\"precision\"],\n",
    "        \"recall\": report[\"micro avg\"][\"recall\"],\n",
    "        \"accuracy\": accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_batches():\n",
    "    batch_numbers = set()\n",
    "    for file in os.listdir(DATA_DIR):\n",
    "        if file.startswith(\"combined_train_\") and file.endswith(\".jsonl\"):\n",
    "            batch_num = file.split(\"_\")[-1].replace(\".jsonl\", \"\")\n",
    "            if batch_num.isdigit():\n",
    "                batch_numbers.add(int(batch_num))\n",
    "    return sorted(batch_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(batch_num):\n",
    "    dataset_prefix = f\"combined_{batch_num}\"\n",
    "\n",
    "    train_file = os.path.join(DATA_DIR, f\"combined_train_{batch_num}.jsonl\")\n",
    "    dev_file = os.path.join(DATA_DIR, f\"combined_dev_{batch_num}.jsonl\")\n",
    "    test_file = os.path.join(DATA_DIR, f\"combined_test_{batch_num}.jsonl\")\n",
    "\n",
    "    if not os.path.exists(train_file) or not os.path.exists(dev_file) or not os.path.exists(test_file):\n",
    "        print(f\"🚨 Skipping batch {batch_num}, files not found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"🚀 Processing batch {batch_num}...\")\n",
    "\n",
    "    \n",
    "    model_path = f\"/media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch{batch_num-1}\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    # Load label2id from Batch 1 to ensure consistent label space\n",
    "    with open(os.path.join(model_path, \"label2id.json\"), \"r\") as f:\n",
    "        old_label2id = json.load(f)\n",
    "    id2label = {v: k for k, v in old_label2id.items()}\n",
    "    print(f\"✅ Loaded label2id from Batch {batch_num - 1}: {old_label2id}\")\n",
    "\n",
    "    train_dataset = preprocess_dataset(load_jsonl(train_file))\n",
    "    dev_dataset = preprocess_dataset(load_jsonl(dev_file))\n",
    "    test_dataset = preprocess_dataset(load_jsonl(test_file))\n",
    "    print(f\"After splitting: Train={len(train_dataset)}, Dev={len(dev_dataset)}, Test={len(test_dataset)}\")\n",
    "\n",
    "    unique_tags = set(tag for example in train_dataset['tags'] for tag in example)\n",
    "    label2id = {tag: i for i, tag in enumerate(sorted(unique_tags))}\n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "    train_dataset = train_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer, label2id))\n",
    "    dev_dataset = dev_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer, label2id))\n",
    "    test_dataset = test_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer, label2id))\n",
    "\n",
    "    # Load the number of labels from batch 1\n",
    "    old_num_labels = len(old_label2id)  # Should match previous training setup\n",
    "    new_num_labels = len(label2id)  # Ensure this matches the new dataset\n",
    "\n",
    "    # Load the previously trained model from batch 1\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_path, num_labels=old_num_labels\n",
    "    )\n",
    "\n",
    "    # Extract the old classifier layer\n",
    "    old_classifier = model.classifier\n",
    "\n",
    "    # Create a new classifier layer with updated label count\n",
    "    new_classifier = nn.Linear(old_classifier.in_features, new_num_labels)\n",
    "\n",
    "    # Transfer weights from the old classifier to the new one (for common labels)\n",
    "    with torch.no_grad():\n",
    "        num_common_labels = min(old_num_labels, new_num_labels)\n",
    "        new_classifier.weight[:num_common_labels, :] = old_classifier.weight[:num_common_labels, :]\n",
    "        new_classifier.bias[:num_common_labels] = old_classifier.bias[:num_common_labels]\n",
    "\n",
    "    # Assign the updated classifier to the model\n",
    "    model.classifier = new_classifier\n",
    "\n",
    "    # Save updated model before continuing training\n",
    "    model.save_pretrained(\"/media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/BioBERT-updated\")\n",
    "    print(f\"✅ Model updated to support new label set while keeping batch {batch_num - 1} training.\")\n",
    "\n",
    "    model_checkpoint = f\"/media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch{batch_num}\"\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(model_checkpoint, exist_ok=True)\n",
    "    print(f\"Directory ensured: {model_checkpoint}\")\n",
    "    model_path_2 = \"/media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/BioBERT-updated\"\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_path_2, num_labels=len(label2id))\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"BioBERT-finetuned-mtl\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_dir=\"./logs\",\n",
    "        learning_rate=3e-5,\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=64,\n",
    "        num_train_epochs=2,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        push_to_hub=False,\n",
    "        save_total_limit=2,\n",
    "        gradient_accumulation_steps=8,  # This simulates batch size 4 * 4 = 16\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=dev_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=lambda p: compute_metrics(p, id2label)\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    metrics = trainer.evaluate(test_dataset)\n",
    "    print(\"Test Set Performance:\")\n",
    "    print(metrics)\n",
    "    \n",
    "    model.save_pretrained(model_checkpoint)\n",
    "    tokenizer.save_pretrained(model_checkpoint)\n",
    "\n",
    "    print(f\"✅ Model trained and saved for batch {batch_num}\")\n",
    "\n",
    "    predictions, labels, _ = trainer.predict(test_dataset)\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # Save label2id to file\n",
    "    with open(f\"{model_checkpoint}/label2id.json\", \"w\") as f:\n",
    "        json.dump(label2id, f)\n",
    "    print(\"✅ Saved new_label2id mapping.\")\n",
    "\n",
    "    # Save label2id to file\n",
    "    with open(\"label2id.json\", \"w\") as f:\n",
    "        json.dump(label2id, f)\n",
    "    print(\"✅ Saved new_label2id mapping.\")\n",
    "    print(\"✅ Saved label2id mapping to model directory.\")\n",
    "\n",
    "    # results = classification_report(labels, predictions, output_dict=True)\n",
    "    # with open(f\"{model_checkpoint}_evaluation.json\", \"w\") as f:\n",
    "    #     json.dump(results, f)\n",
    "\n",
    "    # print(f\"📊 Evaluation results saved for batch {batch_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Detected batches: [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "🚀 Processing batch 21...\n",
      "✅ Loaded label2id from Batch 20: {'B-Protein': 0, 'E-Protein': 1, 'I-Protein': 2, 'O': 3, 'S-Protein': 4}\n",
      "After splitting: Train=81856, Dev=22917, Test=61643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b03912227eb44bc8b9f57b5c168eae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b92dabe880b4f12aa6f6855bd2b44ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5779e380f647b6a69047d421726ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 20 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 03:34, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.404564</td>\n",
       "      <td>0.704550</td>\n",
       "      <td>0.718675</td>\n",
       "      <td>0.690970</td>\n",
       "      <td>0.925895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.3382920026779175, 'eval_f1': 0.6870533642691415, 'eval_precision': 0.7527964205816555, 'eval_recall': 0.6318709457152611, 'eval_accuracy': 0.9234769139991149, 'eval_runtime': 13.9482, 'eval_samples_per_second': 4419.432, 'eval_steps_per_second': 69.113, 'epoch': 1.9882720875684128}\n",
      "✅ Model trained and saved for batch 21\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 22...\n",
      "✅ Loaded label2id from Batch 21: {'B-Chemical': 0, 'B-Organism': 1, 'B-Protein': 2, 'B-Regulon-operon': 3, 'I-Chemical': 4, 'I-Organism': 5, 'I-Protein': 6, 'I-Regulon-operon': 7, 'O': 8}\n",
      "After splitting: Train=81856, Dev=22917, Test=61643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87333776869e47be9d38eb4fbc71c166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f5cb1d14f740f09d0d6bff0b70d243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41eba18ed5444c2b940c5d7f71c034bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 21 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 03:15, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.431468</td>\n",
       "      <td>0.709128</td>\n",
       "      <td>0.707398</td>\n",
       "      <td>0.710867</td>\n",
       "      <td>0.918845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.3785388767719269, 'eval_f1': 0.7443956733030255, 'eval_precision': 0.8120564343736639, 'eval_recall': 0.687142753780479, 'eval_accuracy': 0.9175345194329345, 'eval_runtime': 10.501, 'eval_samples_per_second': 5870.199, 'eval_steps_per_second': 91.801, 'epoch': 1.9882720875684128}\n",
      "✅ Model trained and saved for batch 22\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 23...\n",
      "✅ Loaded label2id from Batch 22: {'B-Chemical': 0, 'B-Organism': 1, 'B-Protein': 2, 'B-Regulon-operon': 3, 'E-Chemical': 4, 'E-Organism': 5, 'E-Protein': 6, 'E-Regulon-operon': 7, 'I-Chemical': 8, 'I-Organism': 9, 'I-Protein': 10, 'O': 11, 'S-Chemical': 12, 'S-Organism': 13, 'S-Protein': 14, 'S-Regulon-operon': 15}\n",
      "After splitting: Train=81856, Dev=22917, Test=61643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf9f5583da7433384a7a3466e4a2c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60d44a69a2e4d1c9f76e6b1c606bdbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca585c0593043e49641d5b1649f2600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 22 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 03:22, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.223500</td>\n",
       "      <td>0.482499</td>\n",
       "      <td>0.773748</td>\n",
       "      <td>0.350548</td>\n",
       "      <td>0.964447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.17072421312332153, 'eval_f1': 0.559647038859664, 'eval_precision': 0.7770970782280867, 'eval_recall': 0.43728453990983823, 'eval_accuracy': 0.9643998623199095, 'eval_runtime': 10.1284, 'eval_samples_per_second': 6086.176, 'eval_steps_per_second': 95.178, 'epoch': 1.9882720875684128}\n",
      "✅ Model trained and saved for batch 23\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 24...\n",
      "✅ Loaded label2id from Batch 23: {'B-Organism': 0, 'I-Organism': 1, 'O': 2}\n",
      "After splitting: Train=81856, Dev=22917, Test=61643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60a73de463b409c85dfdc180bb674c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472f291ecfd241e8ab85c2646c08dc78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20701286b568401bb5ac977e7c7e1eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 23 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 03:19, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263307</td>\n",
       "      <td>0.600872</td>\n",
       "      <td>0.799578</td>\n",
       "      <td>0.481270</td>\n",
       "      <td>0.961580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.2173120230436325, 'eval_f1': 0.7407260464193612, 'eval_precision': 0.8391011235955056, 'eval_recall': 0.6629971590909091, 'eval_accuracy': 0.9596671092098146, 'eval_runtime': 10.1688, 'eval_samples_per_second': 6061.945, 'eval_steps_per_second': 94.799, 'epoch': 1.9882720875684128}\n",
      "✅ Model trained and saved for batch 24\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 25...\n",
      "✅ Loaded label2id from Batch 24: {'B-Organism': 0, 'E-Organism': 1, 'I-Organism': 2, 'O': 3, 'S-Organism': 4}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397e325e000d4bba81f1a64c737bf446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f4fd22dde04646973c4e850a78fbce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625d44d1153a45f895de05eb1f3151c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 24 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:15, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.017044</td>\n",
       "      <td>0.693587</td>\n",
       "      <td>0.719212</td>\n",
       "      <td>0.669725</td>\n",
       "      <td>0.995947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.016075801104307175, 'eval_f1': 0.7047387606318348, 'eval_precision': 0.7512953367875648, 'eval_recall': 0.6636155606407322, 'eval_accuracy': 0.9964218892970788, 'eval_runtime': 8.7404, 'eval_samples_per_second': 6037.621, 'eval_steps_per_second': 94.39, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 25\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 26...\n",
      "✅ Loaded label2id from Batch 25: {'B-Cellular_component': 0, 'I-Cellular_component': 1, 'O': 2}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe466f539904310a2d3effaccb88f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a14f20aba84d9b907c314eb8e930da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0693350f262743819ba1c868571c8a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 25 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:28, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.020405</td>\n",
       "      <td>0.640693</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>0.995167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.017448056489229202, 'eval_f1': 0.7106842737094837, 'eval_precision': 0.7688311688311689, 'eval_recall': 0.6607142857142857, 'eval_accuracy': 0.9964218892970788, 'eval_runtime': 8.7582, 'eval_samples_per_second': 6025.314, 'eval_steps_per_second': 94.197, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 26\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 27...\n",
      "✅ Loaded label2id from Batch 26: {'B-Cellular_component': 0, 'E-Cellular_component': 1, 'I-Cellular_component': 2, 'O': 3, 'S-Cellular_component': 4}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1176484c89d44d1bf240f1b892bc3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5baa457e7ef645eba2963c7dcb9620ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486e8027c5ad4a42968c19b587d722d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 26 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:17, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.125807</td>\n",
       "      <td>0.581958</td>\n",
       "      <td>0.584024</td>\n",
       "      <td>0.579906</td>\n",
       "      <td>0.957856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.1265675574541092, 'eval_f1': 0.5994991898659597, 'eval_precision': 0.5983534254630991, 'eval_recall': 0.6006493506493507, 'eval_accuracy': 0.9567075918768693, 'eval_runtime': 8.7376, 'eval_samples_per_second': 6039.537, 'eval_steps_per_second': 94.42, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 27\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 28...\n",
      "✅ Loaded label2id from Batch 27: {'B-Cell': 0, 'I-Cell': 1, 'O': 2}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b9dc0a97164345b4e16b4e1902e1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99275ea0f1e24a74aa8d68e913c116c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a948dd07aef748b684b4987df4a07078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 27 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:26, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.151064</td>\n",
       "      <td>0.597486</td>\n",
       "      <td>0.613077</td>\n",
       "      <td>0.582668</td>\n",
       "      <td>0.954660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.15368005633354187, 'eval_f1': 0.5949862338791481, 'eval_precision': 0.6002923976608188, 'eval_recall': 0.5897730537201954, 'eval_accuracy': 0.9522008112205181, 'eval_runtime': 8.791, 'eval_samples_per_second': 6002.858, 'eval_steps_per_second': 93.846, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 28\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 29...\n",
      "✅ Loaded label2id from Batch 28: {'B-Cell': 0, 'E-Cell': 1, 'I-Cell': 2, 'O': 3, 'S-Cell': 4}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2a3cfd2b2f4e149951439cbe979b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b68f135f0e4170a3b9bb38ecb5455a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06d77e8b887430da63988b6ecd0bc8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 28 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:30, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.119994</td>\n",
       "      <td>0.619250</td>\n",
       "      <td>0.722543</td>\n",
       "      <td>0.541796</td>\n",
       "      <td>0.970276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.10238754004240036, 'eval_f1': 0.5798718743542055, 'eval_precision': 0.6418115279048491, 'eval_recall': 0.5288352808141726, 'eval_accuracy': 0.9709107793999153, 'eval_runtime': 8.6862, 'eval_samples_per_second': 6075.249, 'eval_steps_per_second': 94.978, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 29\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 30...\n",
      "✅ Loaded label2id from Batch 29: {'B-Simple_chemical': 0, 'I-Simple_chemical': 1, 'O': 2}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f5ec17b13f4ab0ab62883f70588ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1d8860234a4a84846bdbafa2539632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47bb0aa1be14927bd40995dda9de4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 29 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:18, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.149271</td>\n",
       "      <td>0.653452</td>\n",
       "      <td>0.779968</td>\n",
       "      <td>0.562251</td>\n",
       "      <td>0.968353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.1390119194984436, 'eval_f1': 0.648207171314741, 'eval_precision': 0.7656470588235295, 'eval_recall': 0.5620034542314335, 'eval_accuracy': 0.9706376411783183, 'eval_runtime': 8.7576, 'eval_samples_per_second': 6025.754, 'eval_steps_per_second': 94.204, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 30\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 31...\n",
      "✅ Loaded label2id from Batch 30: {'B-Simple_chemical': 0, 'E-Simple_chemical': 1, 'I-Simple_chemical': 2, 'O': 3, 'S-Simple_chemical': 4}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5cd006b23054f9db7121a209534d50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff772c1080f4bfda73d7eb4572cb766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7836e3f38cce4a7a9fb9824c8bb42c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 30 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:11, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.229169</td>\n",
       "      <td>0.710831</td>\n",
       "      <td>0.780961</td>\n",
       "      <td>0.652258</td>\n",
       "      <td>0.921324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.1965653896331787, 'eval_f1': 0.7310701817744071, 'eval_precision': 0.7832086664947124, 'eval_recall': 0.6854401805869075, 'eval_accuracy': 0.934597052838589, 'eval_runtime': 8.79, 'eval_samples_per_second': 6003.545, 'eval_steps_per_second': 93.857, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 31\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 32...\n",
      "✅ Loaded label2id from Batch 31: {'B-Gene_or_gene_product': 0, 'I-Gene_or_gene_product': 1, 'O': 2}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f90b01caeb417eba611ed0c8c873fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670aca0017cd45c0867e2f818c393001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16328d04fd9d4f46b744fcd5e8bbe901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 31 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:28, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.345635</td>\n",
       "      <td>0.742909</td>\n",
       "      <td>0.833371</td>\n",
       "      <td>0.670163</td>\n",
       "      <td>0.902253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.2820952236652374, 'eval_f1': 0.7694593303974107, 'eval_precision': 0.7792584631918323, 'eval_recall': 0.7599035841542654, 'eval_accuracy': 0.91605096759215, 'eval_runtime': 8.7881, 'eval_samples_per_second': 6004.836, 'eval_steps_per_second': 93.877, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 32\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 33...\n",
      "✅ Loaded label2id from Batch 32: {'B-Gene_or_gene_product': 0, 'E-Gene_or_gene_product': 1, 'I-Gene_or_gene_product': 2, 'O': 3, 'S-Gene_or_gene_product': 4}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8bef9c50404fdc835b4c03cdada851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8176df6216ec41139e872bb95875c622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c57a8bf4e040be826dc0daf522a5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 32 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:19, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.674437</td>\n",
       "      <td>0.632400</td>\n",
       "      <td>0.641254</td>\n",
       "      <td>0.623786</td>\n",
       "      <td>0.823239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.6371275782585144, 'eval_f1': 0.6318556408070475, 'eval_precision': 0.6372581800812037, 'eval_recall': 0.626543934626403, 'eval_accuracy': 0.8310093822979119, 'eval_runtime': 9.3076, 'eval_samples_per_second': 5669.664, 'eval_steps_per_second': 88.637, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 33\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 34...\n",
      "✅ Loaded label2id from Batch 33: {'B-Amino_acid': 0, 'B-Anatomical_system': 1, 'B-Cancer': 2, 'B-Cell': 3, 'B-Cellular_component': 4, 'B-Developing_anatomical_structure': 5, 'B-Gene_or_gene_product': 6, 'B-Immaterial_anatomical_entity': 7, 'B-Multi-tissue_structure': 8, 'B-Organ': 9, 'B-Organism': 10, 'B-Organism_subdivision': 11, 'B-Organism_substance': 12, 'B-Pathological_formation': 13, 'B-Simple_chemical': 14, 'B-Tissue': 15, 'I-Amino_acid': 16, 'I-Anatomical_system': 17, 'I-Cancer': 18, 'I-Cell': 19, 'I-Cellular_component': 20, 'I-Developing_anatomical_structure': 21, 'I-Gene_or_gene_product': 22, 'I-Immaterial_anatomical_entity': 23, 'I-Multi-tissue_structure': 24, 'I-Organ': 25, 'I-Organism': 26, 'I-Organism_subdivision': 27, 'I-Organism_substance': 28, 'I-Pathological_formation': 29, 'I-Simple_chemical': 30, 'I-Tissue': 31, 'O': 32}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa84e3302c1a4a16b659168599815871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142e3bbfd7394dc5bf918cfa40c007df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657d69399fb24716b8e5c8bdc369361b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 33 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:21, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.849866</td>\n",
       "      <td>0.671527</td>\n",
       "      <td>0.715021</td>\n",
       "      <td>0.633022</td>\n",
       "      <td>0.796575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.7754917740821838, 'eval_f1': 0.6850002280293702, 'eval_precision': 0.7212484993997599, 'eval_recall': 0.6522211125103131, 'eval_accuracy': 0.8136796962495562, 'eval_runtime': 9.4314, 'eval_samples_per_second': 5595.26, 'eval_steps_per_second': 87.474, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 34\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 35...\n",
      "✅ Loaded label2id from Batch 34: {'B-Amino_acid': 0, 'B-Anatomical_system': 1, 'B-Cancer': 2, 'B-Cell': 3, 'B-Cellular_component': 4, 'B-Developing_anatomical_structure': 5, 'B-Gene_or_gene_product': 6, 'B-Immaterial_anatomical_entity': 7, 'B-Multi-tissue_structure': 8, 'B-Organ': 9, 'B-Organism': 10, 'B-Organism_subdivision': 11, 'B-Organism_substance': 12, 'B-Pathological_formation': 13, 'B-Simple_chemical': 14, 'B-Tissue': 15, 'E-Amino_acid': 16, 'E-Anatomical_system': 17, 'E-Cancer': 18, 'E-Cell': 19, 'E-Cellular_component': 20, 'E-Developing_anatomical_structure': 21, 'E-Gene_or_gene_product': 22, 'E-Immaterial_anatomical_entity': 23, 'E-Multi-tissue_structure': 24, 'E-Organ': 25, 'E-Organism': 26, 'E-Organism_subdivision': 27, 'E-Organism_substance': 28, 'E-Pathological_formation': 29, 'E-Simple_chemical': 30, 'E-Tissue': 31, 'I-Amino_acid': 32, 'I-Anatomical_system': 33, 'I-Cancer': 34, 'I-Cell': 35, 'I-Cellular_component': 36, 'I-Gene_or_gene_product': 37, 'I-Immaterial_anatomical_entity': 38, 'I-Multi-tissue_structure': 39, 'I-Organism': 40, 'I-Organism_substance': 41, 'I-Pathological_formation': 42, 'I-Simple_chemical': 43, 'I-Tissue': 44, 'O': 45, 'S-Amino_acid': 46, 'S-Anatomical_system': 47, 'S-Cancer': 48, 'S-Cell': 49, 'S-Cellular_component': 50, 'S-Developing_anatomical_structure': 51, 'S-Gene_or_gene_product': 52, 'S-Immaterial_anatomical_entity': 53, 'S-Multi-tissue_structure': 54, 'S-Organ': 55, 'S-Organism': 56, 'S-Organism_subdivision': 57, 'S-Organism_substance': 58, 'S-Pathological_formation': 59, 'S-Simple_chemical': 60, 'S-Tissue': 61}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0afe644932ff41969aec42d8e295c3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213d90bc17a447afb99b9218d94c46f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6938b1af998b42d59b169a9ea246e455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 34 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:14, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.029292</td>\n",
       "      <td>0.779949</td>\n",
       "      <td>0.780612</td>\n",
       "      <td>0.779287</td>\n",
       "      <td>0.992101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.031636957079172134, 'eval_f1': 0.7373219373219374, 'eval_precision': 0.7261503928170595, 'eval_recall': 0.7488425925925926, 'eval_accuracy': 0.9922838452398837, 'eval_runtime': 8.2867, 'eval_samples_per_second': 6368.172, 'eval_steps_per_second': 99.557, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 35\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 36...\n",
      "✅ Loaded label2id from Batch 35: {'B-Organism': 0, 'I-Organism': 1, 'O': 2}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a4af14f5c64e9cb1a5041ea75a9c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecedf21651794f0c8728fce737765c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6049fc18ce5348c7a1b9b8bc0b0d4526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 35 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:22, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.039560</td>\n",
       "      <td>0.816598</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.794830</td>\n",
       "      <td>0.991504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.038125406950712204, 'eval_f1': 0.7765089722675367, 'eval_precision': 0.7880794701986755, 'eval_recall': 0.7652733118971061, 'eval_accuracy': 0.9921882468623247, 'eval_runtime': 8.3062, 'eval_samples_per_second': 6353.217, 'eval_steps_per_second': 99.324, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 36\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 37...\n",
      "✅ Loaded label2id from Batch 36: {'B-Organism': 0, 'E-Organism': 1, 'I-Organism': 2, 'O': 3, 'S-Organism': 4}\n",
      "After splitting: Train=75068, Dev=81071, Test=104643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a83a29d5f54d0abec337660b658d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75068 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec405feb7c547df9a5c226c3ba6c790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81071 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecbf24a7019498b871a184a930e92e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/104643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 36 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [292/292 03:27, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.246165</td>\n",
       "      <td>0.675911</td>\n",
       "      <td>0.808020</td>\n",
       "      <td>0.580931</td>\n",
       "      <td>0.925192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242448</td>\n",
       "      <td>0.667994</td>\n",
       "      <td>0.791221</td>\n",
       "      <td>0.577978</td>\n",
       "      <td>0.923065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.26181691884994507, 'eval_f1': 0.6565110919043502, 'eval_precision': 0.7569969271655178, 'eval_recall': 0.5795765244484008, 'eval_accuracy': 0.9268153701453394, 'eval_runtime': 17.4302, 'eval_samples_per_second': 6003.543, 'eval_steps_per_second': 93.86, 'epoch': 1.9957374254049447}\n",
      "✅ Model trained and saved for batch 37\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 38...\n",
      "✅ Loaded label2id from Batch 37: {'B-Protein': 0, 'I-Protein': 1, 'O': 2}\n",
      "After splitting: Train=75068, Dev=81071, Test=104643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc570a4e8564636b928bf4f8acc7fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75068 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c18bf38208c4a559cf92c7b94eac328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81071 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9d0c45135840248e121a0bc52ea75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/104643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 37 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [292/292 03:27, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.309494</td>\n",
       "      <td>0.699785</td>\n",
       "      <td>0.805956</td>\n",
       "      <td>0.618331</td>\n",
       "      <td>0.924497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.318969</td>\n",
       "      <td>0.672706</td>\n",
       "      <td>0.812554</td>\n",
       "      <td>0.573927</td>\n",
       "      <td>0.920137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.32413554191589355, 'eval_f1': 0.6563930841249231, 'eval_precision': 0.7499219237976265, 'eval_recall': 0.5836067565925386, 'eval_accuracy': 0.9239181924906803, 'eval_runtime': 17.7416, 'eval_samples_per_second': 5898.165, 'eval_steps_per_second': 92.213, 'epoch': 1.9957374254049447}\n",
      "✅ Model trained and saved for batch 38\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 39...\n",
      "✅ Loaded label2id from Batch 38: {'B-Protein': 0, 'E-Protein': 1, 'I-Protein': 2, 'O': 3, 'S-Protein': 4}\n",
      "After splitting: Train=69244, Dev=23646, Test=46196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963681e6fe8940cf8b7a1b9c49f80086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/69244 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc4d42b27ea483b99c968aa6a8fa72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23646 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e321154c4b54fbc904b9665511c41da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46196 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 38 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 02:52, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.035732</td>\n",
       "      <td>0.804270</td>\n",
       "      <td>0.798587</td>\n",
       "      <td>0.810036</td>\n",
       "      <td>0.992774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.01997540518641472, 'eval_f1': 0.8114704087858451, 'eval_precision': 0.8407079646017699, 'eval_recall': 0.7841981132075472, 'eval_accuracy': 0.9952293905212002, 'eval_runtime': 7.5446, 'eval_samples_per_second': 6123.094, 'eval_steps_per_second': 95.698, 'epoch': 1.990757855822551}\n",
      "✅ Model trained and saved for batch 39\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 40...\n",
      "✅ Loaded label2id from Batch 39: {'B-Cellular_component': 0, 'I-Cellular_component': 1, 'O': 2}\n",
      "After splitting: Train=69244, Dev=23646, Test=46196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3cc7f3ee4f4cdc8d017077f1aa2abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/69244 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3633dcbd730d4fd3bf6232812cf1b7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23646 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902a1265d5c14c3a84eaf88f33432e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46196 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 39 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/BioBERT/biobert-finetuned-batch40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_149603/2071289192.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 03:01, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.042256</td>\n",
       "      <td>0.813389</td>\n",
       "      <td>0.803306</td>\n",
       "      <td>0.823729</td>\n",
       "      <td>0.991730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.02628585882484913, 'eval_f1': 0.8385624643468339, 'eval_precision': 0.8526682134570766, 'eval_recall': 0.8249158249158249, 'eval_accuracy': 0.9943228261031105, 'eval_runtime': 7.523, 'eval_samples_per_second': 6140.645, 'eval_steps_per_second': 95.973, 'epoch': 1.990757855822551}\n",
      "✅ Model trained and saved for batch 40\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🎉 All detected batches processed successfully!\n"
     ]
    }
   ],
   "source": [
    "batch_numbers = detect_batches()\n",
    "print(f\"📝 Detected batches: {batch_numbers}\")\n",
    "\n",
    "for batch_num in batch_numbers:\n",
    "    train_and_evaluate(batch_num)\n",
    "\n",
    "print(\"🎉 All detected batches processed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
