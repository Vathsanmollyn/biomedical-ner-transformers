{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import numpy as np\n",
    "from seqeval.metrics import classification_report, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512  # BERT's max sequence length\n",
    "DATA_DIR = \"/media/smartdragon/WORK/6th Semester/22AIE315 - Natural Language Processing/Project/New_Json_Files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(filepath):\n",
    "    data = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return Dataset.from_list(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_long_sentence(tokens, tags, max_len=MAX_LEN - 2):  # -2 for [CLS] and [SEP]\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), max_len):\n",
    "        chunk_tokens = tokens[i:i+max_len]\n",
    "        chunk_tags = tags[i:i+max_len]\n",
    "        chunks.append({'tokens': chunk_tokens, 'tags': chunk_tags})\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    split_data = []\n",
    "    for example in dataset:\n",
    "        split_sentences = split_long_sentence(example['tokens'], example['tags'])\n",
    "        split_data.extend(split_sentences)\n",
    "    return Dataset.from_list(split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(example, tokenizer, label2id):\n",
    "    tokenized = tokenizer(example['tokens'], truncation=True, max_length=512, is_split_into_words=True)\n",
    "    word_ids = tokenized.word_ids()\n",
    "\n",
    "    aligned_labels = []\n",
    "    previous_word_idx = None\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            aligned_labels.append(-100)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            aligned_labels.append(label2id.get(example['tags'][word_idx], -100))\n",
    "        else:\n",
    "            aligned_labels.append(label2id.get(example['tags'][word_idx], -100))\n",
    "\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    tokenized['labels'] = aligned_labels\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p, id2label):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_labels = []\n",
    "    true_predictions = []\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        label_sequence = []\n",
    "        prediction_sequence = []\n",
    "\n",
    "        for j in range(len(labels[i])):\n",
    "            if labels[i][j] != -100:  # Exclude padding tokens\n",
    "                label_sequence.append(id2label.get(labels[i][j], \"O\"))\n",
    "                prediction_sequence.append(id2label.get(predictions[i][j], \"O\"))\n",
    "\n",
    "        true_labels.append(label_sequence)\n",
    "        true_predictions.append(prediction_sequence)\n",
    "\n",
    "    report = classification_report(true_labels, true_predictions, output_dict=True)\n",
    "    accuracy = accuracy_score(true_labels, true_predictions)\n",
    "\n",
    "    return {\n",
    "        \"f1\": report[\"micro avg\"][\"f1-score\"],\n",
    "        \"precision\": report[\"micro avg\"][\"precision\"],\n",
    "        \"recall\": report[\"micro avg\"][\"recall\"],\n",
    "        \"accuracy\": accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_batches():\n",
    "    batch_numbers = set()\n",
    "    for file in os.listdir(DATA_DIR):\n",
    "        if file.startswith(\"combined_train_\") and file.endswith(\".jsonl\"):\n",
    "            batch_num = file.split(\"_\")[-1].replace(\".jsonl\", \"\")\n",
    "            if batch_num.isdigit():\n",
    "                batch_numbers.add(int(batch_num))\n",
    "    return sorted(batch_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(batch_num):\n",
    "    dataset_prefix = f\"combined_{batch_num}\"\n",
    "\n",
    "    train_file = os.path.join(DATA_DIR, f\"combined_train_{batch_num}.jsonl\")\n",
    "    dev_file = os.path.join(DATA_DIR, f\"combined_dev_{batch_num}.jsonl\")\n",
    "    test_file = os.path.join(DATA_DIR, f\"combined_test_{batch_num}.jsonl\")\n",
    "\n",
    "    if not os.path.exists(train_file) or not os.path.exists(dev_file) or not os.path.exists(test_file):\n",
    "        print(f\"🚨 Skipping batch {batch_num}, files not found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"🚀 Processing batch {batch_num}...\")\n",
    "\n",
    "    \n",
    "    model_path = f\"/media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch{batch_num-1}\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    # Load label2id from Batch 1 to ensure consistent label space\n",
    "    with open(os.path.join(model_path, \"label2id.json\"), \"r\") as f:\n",
    "        old_label2id = json.load(f)\n",
    "    id2label = {v: k for k, v in old_label2id.items()}\n",
    "    print(f\"✅ Loaded label2id from Batch {batch_num - 1}: {old_label2id}\")\n",
    "\n",
    "    train_dataset = preprocess_dataset(load_jsonl(train_file))\n",
    "    dev_dataset = preprocess_dataset(load_jsonl(dev_file))\n",
    "    test_dataset = preprocess_dataset(load_jsonl(test_file))\n",
    "    print(f\"After splitting: Train={len(train_dataset)}, Dev={len(dev_dataset)}, Test={len(test_dataset)}\")\n",
    "\n",
    "    unique_tags = set(tag for example in train_dataset['tags'] for tag in example)\n",
    "    label2id = {tag: i for i, tag in enumerate(sorted(unique_tags))}\n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "    train_dataset = train_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer, label2id))\n",
    "    dev_dataset = dev_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer, label2id))\n",
    "    test_dataset = test_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer, label2id))\n",
    "\n",
    "    # Load the number of labels from batch 1\n",
    "    old_num_labels = len(old_label2id)  # Should match previous training setup\n",
    "    new_num_labels = len(label2id)  # Ensure this matches the new dataset\n",
    "\n",
    "    # Load the previously trained model from batch 1\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_path, num_labels=old_num_labels\n",
    "    )\n",
    "\n",
    "    # Extract the old classifier layer\n",
    "    old_classifier = model.classifier\n",
    "\n",
    "    # Create a new classifier layer with updated label count\n",
    "    new_classifier = nn.Linear(old_classifier.in_features, new_num_labels)\n",
    "\n",
    "    # Transfer weights from the old classifier to the new one (for common labels)\n",
    "    with torch.no_grad():\n",
    "        num_common_labels = min(old_num_labels, new_num_labels)\n",
    "        new_classifier.weight[:num_common_labels, :] = old_classifier.weight[:num_common_labels, :]\n",
    "        new_classifier.bias[:num_common_labels] = old_classifier.bias[:num_common_labels]\n",
    "\n",
    "    # Assign the updated classifier to the model\n",
    "    model.classifier = new_classifier\n",
    "\n",
    "    # Save updated model before continuing training\n",
    "    model.save_pretrained(\"/media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/PubMedBERT-updated\")\n",
    "    print(f\"✅ Model updated to support new label set while keeping batch {batch_num - 1} training.\")\n",
    "\n",
    "    model_checkpoint = f\"/media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch{batch_num}\"\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(model_checkpoint, exist_ok=True)\n",
    "    print(f\"Directory ensured: {model_checkpoint}\")\n",
    "    model_path_2 = \"/media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/PubMedBERT-updated\"\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_path_2, num_labels=len(label2id))\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"PubMedBERT-finetuned-mtl\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_dir=\"./logs\",\n",
    "        learning_rate=3e-5,\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=64,\n",
    "        num_train_epochs=2,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        push_to_hub=False,\n",
    "        save_total_limit=2,\n",
    "        gradient_accumulation_steps=8,  # This simulates batch size 4 * 4 = 16\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=dev_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=lambda p: compute_metrics(p, id2label)\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    metrics = trainer.evaluate(test_dataset)\n",
    "    print(\"Test Set Performance:\")\n",
    "    print(metrics)\n",
    "    \n",
    "    model.save_pretrained(model_checkpoint)\n",
    "    tokenizer.save_pretrained(model_checkpoint)\n",
    "\n",
    "    print(f\"✅ Model trained and saved for batch {batch_num}\")\n",
    "\n",
    "    predictions, labels, _ = trainer.predict(test_dataset)\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # Save label2id to file\n",
    "    with open(f\"{model_checkpoint}/label2id.json\", \"w\") as f:\n",
    "        json.dump(label2id, f)\n",
    "    print(\"✅ Saved new_label2id mapping.\")\n",
    "\n",
    "    # Save label2id to file\n",
    "    with open(\"label2id.json\", \"w\") as f:\n",
    "        json.dump(label2id, f)\n",
    "    print(\"✅ Saved new_label2id mapping.\")\n",
    "    print(\"✅ Saved label2id mapping to model directory.\")\n",
    "\n",
    "    # results = classification_report(labels, predictions, output_dict=True)\n",
    "    # with open(f\"{model_checkpoint}_evaluation.json\", \"w\") as f:\n",
    "    #     json.dump(results, f)\n",
    "\n",
    "    # print(f\"📊 Evaluation results saved for batch {batch_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Detected batches: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "🚀 Processing batch 2...\n",
      "✅ Loaded label2id from Batch 1: {'B-Anatomy': 0, 'I-Anatomy': 1, 'O': 2}\n",
      "After splitting: Train=153823, Dev=58785, Test=99976\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ac6751524d4257930eafd5834ebb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/153823 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6aa466476642a792b95df64b594d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/58785 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195b2b99814646589d82090800c9ae03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/99976 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 1 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 04:38, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.146200</td>\n",
       "      <td>0.124860</td>\n",
       "      <td>0.832854</td>\n",
       "      <td>0.868646</td>\n",
       "      <td>0.799895</td>\n",
       "      <td>0.963944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.16592392325401306, 'eval_f1': 0.8233893206317373, 'eval_precision': 0.8807991418610888, 'eval_recall': 0.773005413038362, 'eval_accuracy': 0.9503705938932161, 'eval_runtime': 14.2027, 'eval_samples_per_second': 7039.241, 'eval_steps_per_second': 110.05, 'epoch': 1.995008319467554}\n",
      "✅ Model trained and saved for batch 2\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 3...\n",
      "✅ Loaded label2id from Batch 2: {'B-Anatomy': 0, 'E-Anatomy': 1, 'I-Anatomy': 2, 'O': 3, 'S-Anatomy': 4}\n",
      "After splitting: Train=355405, Dev=71042, Test=143465\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de31aa4bd51d4b9fa7e1b9d366773014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/355405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be624a9875d94582a29362564629baca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/71042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984132bd19164118a7fdbaf09d52956b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/143465 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 2 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1388' max='1388' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1388/1388 07:58, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.209500</td>\n",
       "      <td>0.217386</td>\n",
       "      <td>0.621465</td>\n",
       "      <td>0.714784</td>\n",
       "      <td>0.549698</td>\n",
       "      <td>0.916433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.21309620141983032, 'eval_f1': 0.6325971105566337, 'eval_precision': 0.7243227990970654, 'eval_recall': 0.5614917701099141, 'eval_accuracy': 0.9181524810999231, 'eval_runtime': 20.9166, 'eval_samples_per_second': 6858.915, 'eval_steps_per_second': 107.188, 'epoch': 1.9981994958588405}\n",
      "✅ Model trained and saved for batch 3\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 4...\n",
      "✅ Loaded label2id from Batch 3: {'B-GENE': 0, 'I-GENE': 1, 'O': 2}\n",
      "After splitting: Train=355405, Dev=71042, Test=143465\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf6e242d156484e82bc3ecdd46b65d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/355405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff0d5077e394b449827dc76e7635a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/71042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16dd5dbd5aea48b7816067879a4fb4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/143465 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 3 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1388' max='1388' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1388/1388 07:56, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.285314</td>\n",
       "      <td>0.614339</td>\n",
       "      <td>0.774875</td>\n",
       "      <td>0.508906</td>\n",
       "      <td>0.902971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.28603553771972656, 'eval_f1': 0.6389875261768188, 'eval_precision': 0.7369784374124895, 'eval_recall': 0.5639967854272703, 'eval_accuracy': 0.9001998331490212, 'eval_runtime': 21.2208, 'eval_samples_per_second': 6760.593, 'eval_steps_per_second': 105.651, 'epoch': 1.9981994958588405}\n",
      "✅ Model trained and saved for batch 4\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 5...\n",
      "✅ Loaded label2id from Batch 4: {'B-GENE': 0, 'E-GENE': 1, 'I-GENE': 2, 'O': 3, 'S-GENE': 4}\n",
      "After splitting: Train=891948, Dev=886324, Test=766033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0d05b7139c45c4be16ecbed7fe2ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/891948 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a58535fb764dd48f6edbb3577ca10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/886324 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b641caafab7a45908474fce746ede50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/766033 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 4 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3484' max='3484' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3484/3484 22:14, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.118900</td>\n",
       "      <td>0.149742</td>\n",
       "      <td>0.646858</td>\n",
       "      <td>0.797908</td>\n",
       "      <td>0.543894</td>\n",
       "      <td>0.948044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.14288094639778137, 'eval_f1': 0.6524522821220168, 'eval_precision': 0.8098824433018285, 'eval_recall': 0.5462656497337747, 'eval_accuracy': 0.9498284816542633, 'eval_runtime': 126.6362, 'eval_samples_per_second': 6049.083, 'eval_steps_per_second': 94.523, 'epoch': 1.9993542369232977}\n",
      "✅ Model trained and saved for batch 5\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 6...\n",
      "✅ Loaded label2id from Batch 5: {'B-Chemical': 0, 'I-Chemical': 1, 'O': 2}\n",
      "After splitting: Train=891948, Dev=886324, Test=766033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013b8fa0b7a448b1aba0d96df69d7fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/891948 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820f1009f78e45cd838d9b8b6c598eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/886324 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555d5d63dc3049eb90502fcf4d09729b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/766033 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 5 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3484' max='3484' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3484/3484 22:43, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.126400</td>\n",
       "      <td>0.193419</td>\n",
       "      <td>0.685091</td>\n",
       "      <td>0.841205</td>\n",
       "      <td>0.577851</td>\n",
       "      <td>0.942504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.18613643944263458, 'eval_f1': 0.6902203991275189, 'eval_precision': 0.8539178766337072, 'eval_recall': 0.5791889196978596, 'eval_accuracy': 0.9442985764457748, 'eval_runtime': 134.5557, 'eval_samples_per_second': 5693.056, 'eval_steps_per_second': 88.959, 'epoch': 1.9993542369232977}\n",
      "✅ Model trained and saved for batch 6\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 7...\n",
      "✅ Loaded label2id from Batch 6: {'B-Chemical': 0, 'E-Chemical': 1, 'I-Chemical': 2, 'O': 3, 'S-Chemical': 4}\n",
      "After splitting: Train=118170, Dev=117453, Test=124750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f508de3ae2240369610c81e67ae4e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/118170 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac69db67e02c4adca581328dc02224c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353fd5f83e98499a974807602ed4e673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 6 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 04:15, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.081355</td>\n",
       "      <td>0.842064</td>\n",
       "      <td>0.924906</td>\n",
       "      <td>0.772843</td>\n",
       "      <td>0.976098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.087129</td>\n",
       "      <td>0.842942</td>\n",
       "      <td>0.912229</td>\n",
       "      <td>0.783437</td>\n",
       "      <td>0.975536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.08824562281370163, 'eval_f1': 0.8382297450272221, 'eval_precision': 0.9059659752971335, 'eval_recall': 0.7799177450095296, 'eval_accuracy': 0.9759617923780924, 'eval_runtime': 17.6669, 'eval_samples_per_second': 7061.214, 'eval_steps_per_second': 110.376, 'epoch': 1.9962100703844072}\n",
      "✅ Model trained and saved for batch 7\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 8...\n",
      "✅ Loaded label2id from Batch 7: {'B-Chemical': 0, 'I-Chemical': 1, 'O': 2}\n",
      "After splitting: Train=118170, Dev=117453, Test=124750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ced08d2a094861b48458dabddd7e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/118170 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765558e1f5eb4a4a9b5d5ea2f1780d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad060fb9360429cbe1c06922fe3b242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 7 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 04:14, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.114982</td>\n",
       "      <td>0.853811</td>\n",
       "      <td>0.920281</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.973159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.122606</td>\n",
       "      <td>0.855141</td>\n",
       "      <td>0.916620</td>\n",
       "      <td>0.801391</td>\n",
       "      <td>0.972717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.12150225788354874, 'eval_f1': 0.8520132835201328, 'eval_precision': 0.9155793464926955, 'eval_recall': 0.7967006307617661, 'eval_accuracy': 0.972355306739903, 'eval_runtime': 17.7711, 'eval_samples_per_second': 7019.84, 'eval_steps_per_second': 109.729, 'epoch': 1.9962100703844072}\n",
      "✅ Model trained and saved for batch 8\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 9...\n",
      "✅ Loaded label2id from Batch 8: {'B-Chemical': 0, 'E-Chemical': 1, 'I-Chemical': 2, 'O': 3, 'S-Chemical': 4}\n",
      "After splitting: Train=118170, Dev=117453, Test=124750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fcfe3c0fdc47119bffc0567481d239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/118170 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcdbef2692e2428aafa3f0dc53e87dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a52de8be7d9466b8cf24bdd6b316abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 8 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 04:17, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.106652</td>\n",
       "      <td>0.749867</td>\n",
       "      <td>0.800598</td>\n",
       "      <td>0.705181</td>\n",
       "      <td>0.963829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.109105</td>\n",
       "      <td>0.745518</td>\n",
       "      <td>0.805446</td>\n",
       "      <td>0.693890</td>\n",
       "      <td>0.963749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.10527325421571732, 'eval_f1': 0.7328531568360263, 'eval_precision': 0.7835437768835855, 'eval_recall': 0.6883227693807898, 'eval_accuracy': 0.9638219693825968, 'eval_runtime': 24.7804, 'eval_samples_per_second': 5034.226, 'eval_steps_per_second': 78.691, 'epoch': 1.9962100703844072}\n",
      "✅ Model trained and saved for batch 9\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 10...\n",
      "✅ Loaded label2id from Batch 9: {'B-Disease': 0, 'I-Disease': 1, 'O': 2}\n",
      "After splitting: Train=118170, Dev=117453, Test=124750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1bbddc003ae490ea532059b76705359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/118170 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b3ed901c2c4c1a8f822b0a9d546d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0dc5a364894f17aaa7c4769362a136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 9 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 04:21, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.128909</td>\n",
       "      <td>0.759368</td>\n",
       "      <td>0.848121</td>\n",
       "      <td>0.687431</td>\n",
       "      <td>0.962408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.126376</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.807864</td>\n",
       "      <td>0.714691</td>\n",
       "      <td>0.961164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.1271507441997528, 'eval_f1': 0.7504099704821253, 'eval_precision': 0.8365019011406845, 'eval_recall': 0.680385393124777, 'eval_accuracy': 0.9627581315688213, 'eval_runtime': 17.764, 'eval_samples_per_second': 7022.619, 'eval_steps_per_second': 109.772, 'epoch': 1.9962100703844072}\n",
      "✅ Model trained and saved for batch 10\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 11...\n",
      "✅ Loaded label2id from Batch 10: {'B-Disease': 0, 'E-Disease': 1, 'I-Disease': 2, 'O': 3, 'S-Disease': 4}\n",
      "After splitting: Train=118170, Dev=117453, Test=124750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bff6f7a275e40959a745f3953ccc529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/118170 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533b5bc017ef40a2aa89685345995aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d134413b4b58480ea5cd6fd1c5464fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 10 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 04:17, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.221064</td>\n",
       "      <td>0.792660</td>\n",
       "      <td>0.841457</td>\n",
       "      <td>0.749213</td>\n",
       "      <td>0.937117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.219173</td>\n",
       "      <td>0.798624</td>\n",
       "      <td>0.844779</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.938971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.21737997233867645, 'eval_f1': 0.7952799280971847, 'eval_precision': 0.8404829023164604, 'eval_recall': 0.7546910251471964, 'eval_accuracy': 0.9406967005937875, 'eval_runtime': 17.8296, 'eval_samples_per_second': 6996.806, 'eval_steps_per_second': 109.369, 'epoch': 1.9962100703844072}\n",
      "✅ Model trained and saved for batch 11\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 12...\n",
      "✅ Loaded label2id from Batch 11: {'B-Chemical': 0, 'B-Disease': 1, 'I-Chemical': 2, 'I-Disease': 3, 'O': 4}\n",
      "After splitting: Train=118170, Dev=117453, Test=124750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd40c698b1a455aa22a5f98812a5c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/118170 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4cf71d57fd149129e8b4e6dbf75a8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393dc47df6284027928509446e1ebc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 11 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 04:14, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.305008</td>\n",
       "      <td>0.800371</td>\n",
       "      <td>0.823608</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.928349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.268078</td>\n",
       "      <td>0.804985</td>\n",
       "      <td>0.846733</td>\n",
       "      <td>0.767160</td>\n",
       "      <td>0.932219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.26242923736572266, 'eval_f1': 0.8113844941163222, 'eval_precision': 0.8572873289708507, 'eval_recall': 0.7701474989311672, 'eval_accuracy': 0.9352190675951984, 'eval_runtime': 18.0747, 'eval_samples_per_second': 6901.914, 'eval_steps_per_second': 107.886, 'epoch': 1.9962100703844072}\n",
      "✅ Model trained and saved for batch 12\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 13...\n",
      "✅ Loaded label2id from Batch 12: {'B-Chemical': 0, 'B-Disease': 1, 'E-Chemical': 2, 'E-Disease': 3, 'I-Chemical': 4, 'I-Disease': 5, 'O': 6, 'S-Chemical': 7, 'S-Disease': 8}\n",
      "After splitting: Train=227742, Dev=44185, Test=74624\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3030a86686d944caa2d6f2c92c8e5837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/227742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e4c6f8a4ac4842aa95481e64c6f18e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44185 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1e873ad1844e3a8ae85c1a9d32ec5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/74624 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 12 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='888' max='888' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [888/888 05:37, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.180592</td>\n",
       "      <td>0.685648</td>\n",
       "      <td>0.763863</td>\n",
       "      <td>0.621963</td>\n",
       "      <td>0.932246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.163700</td>\n",
       "      <td>0.183367</td>\n",
       "      <td>0.676672</td>\n",
       "      <td>0.799478</td>\n",
       "      <td>0.586570</td>\n",
       "      <td>0.933695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.17530813813209534, 'eval_f1': 0.6889756460308607, 'eval_precision': 0.7629700796047214, 'eval_recall': 0.628064625466049, 'eval_accuracy': 0.9333707249295721, 'eval_runtime': 10.1638, 'eval_samples_per_second': 7342.114, 'eval_steps_per_second': 114.721, 'epoch': 1.998033155380725}\n",
      "✅ Model trained and saved for batch 13\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 14...\n",
      "✅ Loaded label2id from Batch 13: {'B-Protein': 0, 'I-Protein': 1, 'O': 2}\n",
      "After splitting: Train=227742, Dev=44185, Test=74624\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb3293631154f0f89c3794d4523ce53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/227742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf030b02dd74a60b9588f9b0e9f47ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44185 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5125730259184792960caaa4a1b80a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/74624 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 13 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='888' max='888' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [888/888 05:46, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.225407</td>\n",
       "      <td>0.684739</td>\n",
       "      <td>0.765504</td>\n",
       "      <td>0.619390</td>\n",
       "      <td>0.927770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.218022</td>\n",
       "      <td>0.677542</td>\n",
       "      <td>0.795861</td>\n",
       "      <td>0.589850</td>\n",
       "      <td>0.930516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.22275350987911224, 'eval_f1': 0.6851463143597974, 'eval_precision': 0.7606579849211789, 'eval_recall': 0.6232730540267326, 'eval_accuracy': 0.929189664622876, 'eval_runtime': 10.1419, 'eval_samples_per_second': 7357.978, 'eval_steps_per_second': 114.968, 'epoch': 1.998033155380725}\n",
      "✅ Model trained and saved for batch 14\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 15...\n",
      "✅ Loaded label2id from Batch 14: {'B-Protein': 0, 'E-Protein': 1, 'I-Protein': 2, 'O': 3, 'S-Protein': 4}\n",
      "After splitting: Train=161576, Dev=54760, Test=116105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c58488d68f24029affbb42e07618162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/161576 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3fa071500034dd68919645bf25c5eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/54760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613643fd5903469d93911fdc8cca618d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/116105 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 14 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [630/630 04:38, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.136600</td>\n",
       "      <td>0.165017</td>\n",
       "      <td>0.718147</td>\n",
       "      <td>0.814148</td>\n",
       "      <td>0.642399</td>\n",
       "      <td>0.948863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.1774095594882965, 'eval_f1': 0.701497070948145, 'eval_precision': 0.8088662063444411, 'eval_recall': 0.6192920625191541, 'eval_accuracy': 0.9440795675947458, 'eval_runtime': 17.1712, 'eval_samples_per_second': 6761.599, 'eval_steps_per_second': 105.7, 'epoch': 1.9948514851485148}\n",
      "✅ Model trained and saved for batch 15\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 16...\n",
      "✅ Loaded label2id from Batch 15: {'B-Protein': 0, 'I-Protein': 1, 'O': 2}\n",
      "After splitting: Train=161576, Dev=54760, Test=116105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cef4e0fec1f487f866c6e320cc5820a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/161576 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e61df677e8d4bdfbff6371ae787e57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/54760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d203d0a7b3784cdea024156d8fd43537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/116105 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 15 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [630/630 04:40, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.222712</td>\n",
       "      <td>0.716246</td>\n",
       "      <td>0.825258</td>\n",
       "      <td>0.632674</td>\n",
       "      <td>0.944646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.24819007515907288, 'eval_f1': 0.6915706274561751, 'eval_precision': 0.8280638680342604, 'eval_recall': 0.5937073540561031, 'eval_accuracy': 0.9381009993086544, 'eval_runtime': 17.4444, 'eval_samples_per_second': 6655.705, 'eval_steps_per_second': 104.045, 'epoch': 1.9948514851485148}\n",
      "✅ Model trained and saved for batch 16\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 17...\n",
      "✅ Loaded label2id from Batch 16: {'B-Protein': 0, 'E-Protein': 1, 'I-Protein': 2, 'O': 3, 'S-Protein': 4}\n",
      "After splitting: Train=81856, Dev=22917, Test=61643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af28360391a347ecb7d09a615b841217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935d3ac301ee4416a0e6fadc5eac0634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbd71f7d8bf4d799744acd23ec783ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 16 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 03:13, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.019927</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.748092</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.994913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.02291898988187313, 'eval_f1': 0.5778688524590164, 'eval_precision': 0.5562130177514792, 'eval_recall': 0.6012793176972282, 'eval_accuracy': 0.9936779581274994, 'eval_runtime': 8.6989, 'eval_samples_per_second': 7086.311, 'eval_steps_per_second': 110.819, 'epoch': 1.9882720875684128}\n",
      "✅ Model trained and saved for batch 17\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 18...\n",
      "✅ Loaded label2id from Batch 17: {'B-Chemical': 0, 'I-Chemical': 1, 'O': 2}\n",
      "After splitting: Train=81856, Dev=22917, Test=61643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa4f39e24d8491290fb3bb1436542f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ceffd94d424016a2599ff49447a81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5137a9552f463ba005e93fc8ce0265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 17 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 03:17, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.024467</td>\n",
       "      <td>0.769531</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.766537</td>\n",
       "      <td>0.995031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.027205992490053177, 'eval_f1': 0.5769622833843017, 'eval_precision': 0.562624254473161, 'eval_recall': 0.5920502092050209, 'eval_accuracy': 0.9936338508586215, 'eval_runtime': 8.7225, 'eval_samples_per_second': 7067.129, 'eval_steps_per_second': 110.519, 'epoch': 1.9882720875684128}\n",
      "✅ Model trained and saved for batch 18\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 19...\n",
      "✅ Loaded label2id from Batch 18: {'B-Chemical': 0, 'E-Chemical': 1, 'I-Chemical': 2, 'O': 3, 'S-Chemical': 4}\n",
      "After splitting: Train=81856, Dev=22917, Test=61643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47da81e0de634a63bcf23e1c6b08bf3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25538db4b2c14a279d4f46f75395e5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d877a0e6eb4f31b0c5ca8620380074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 18 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 03:12, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.089955</td>\n",
       "      <td>0.845861</td>\n",
       "      <td>0.794727</td>\n",
       "      <td>0.904027</td>\n",
       "      <td>0.969321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.09900033473968506, 'eval_f1': 0.8239383690341978, 'eval_precision': 0.8093392395717978, 'eval_recall': 0.8390738614619212, 'eval_accuracy': 0.9724476593742649, 'eval_runtime': 8.7817, 'eval_samples_per_second': 7019.494, 'eval_steps_per_second': 109.774, 'epoch': 1.9882720875684128}\n",
      "✅ Model trained and saved for batch 19\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 20...\n",
      "✅ Loaded label2id from Batch 19: {'B-Protein': 0, 'I-Protein': 1, 'O': 2}\n",
      "After splitting: Train=81856, Dev=22917, Test=61643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8e22e80c864132928d2a3a6867f523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee922e625c2430184f34b78091df4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1479faad84a14570a826e3da64c35500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 19 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_180141/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 03:17, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.155230</td>\n",
       "      <td>0.827409</td>\n",
       "      <td>0.769090</td>\n",
       "      <td>0.895299</td>\n",
       "      <td>0.961276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.14952348172664642, 'eval_f1': 0.8477768722267499, 'eval_precision': 0.8139454007998609, 'eval_recall': 0.8845427059712774, 'eval_accuracy': 0.9729769466007998, 'eval_runtime': 8.7406, 'eval_samples_per_second': 7052.489, 'eval_steps_per_second': 110.29, 'epoch': 1.9882720875684128}\n",
      "✅ Model trained and saved for batch 20\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🎉 All detected batches processed successfully!\n"
     ]
    }
   ],
   "source": [
    "batch_numbers = detect_batches()\n",
    "print(f\"📝 Detected batches: {batch_numbers}\")\n",
    "\n",
    "for batch_num in batch_numbers:\n",
    "    train_and_evaluate(batch_num)\n",
    "\n",
    "print(\"🎉 All detected batches processed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
