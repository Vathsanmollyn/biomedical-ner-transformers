{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import numpy as np\n",
    "from seqeval.metrics import classification_report, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512  # BERT's max sequence length\n",
    "DATA_DIR = \"/media/smartdragon/WORK/6th Semester/22AIE315 - Natural Language Processing/Project/New_Json_Files/Batch 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(filepath):\n",
    "    data = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return Dataset.from_list(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_long_sentence(tokens, tags, max_len=MAX_LEN - 2):  # -2 for [CLS] and [SEP]\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), max_len):\n",
    "        chunk_tokens = tokens[i:i+max_len]\n",
    "        chunk_tags = tags[i:i+max_len]\n",
    "        chunks.append({'tokens': chunk_tokens, 'tags': chunk_tags})\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    split_data = []\n",
    "    for example in dataset:\n",
    "        split_sentences = split_long_sentence(example['tokens'], example['tags'])\n",
    "        split_data.extend(split_sentences)\n",
    "    return Dataset.from_list(split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(example, tokenizer, label2id):\n",
    "    tokenized = tokenizer(example['tokens'], truncation=True, max_length=512, is_split_into_words=True)\n",
    "    word_ids = tokenized.word_ids()\n",
    "\n",
    "    aligned_labels = []\n",
    "    previous_word_idx = None\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            aligned_labels.append(-100)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            aligned_labels.append(label2id.get(example['tags'][word_idx], -100))\n",
    "        else:\n",
    "            aligned_labels.append(label2id.get(example['tags'][word_idx], -100))\n",
    "\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    tokenized['labels'] = aligned_labels\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p, id2label):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_labels = []\n",
    "    true_predictions = []\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        label_sequence = []\n",
    "        prediction_sequence = []\n",
    "\n",
    "        for j in range(len(labels[i])):\n",
    "            if labels[i][j] != -100:  # Exclude padding tokens\n",
    "                label_sequence.append(id2label.get(labels[i][j], \"O\"))\n",
    "                prediction_sequence.append(id2label.get(predictions[i][j], \"O\"))\n",
    "\n",
    "        true_labels.append(label_sequence)\n",
    "        true_predictions.append(prediction_sequence)\n",
    "\n",
    "    report = classification_report(true_labels, true_predictions, output_dict=True)\n",
    "    accuracy = accuracy_score(true_labels, true_predictions)\n",
    "\n",
    "    return {\n",
    "        \"f1\": report[\"micro avg\"][\"f1-score\"],\n",
    "        \"precision\": report[\"micro avg\"][\"precision\"],\n",
    "        \"recall\": report[\"micro avg\"][\"recall\"],\n",
    "        \"accuracy\": accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_batches():\n",
    "    batch_numbers = set()\n",
    "    for file in os.listdir(DATA_DIR):\n",
    "        if file.startswith(\"combined_train_\") and file.endswith(\".jsonl\"):\n",
    "            batch_num = file.split(\"_\")[-1].replace(\".jsonl\", \"\")\n",
    "            if batch_num.isdigit():\n",
    "                batch_numbers.add(int(batch_num))\n",
    "    return sorted(batch_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(batch_num):\n",
    "    dataset_prefix = f\"combined_{batch_num}\"\n",
    "\n",
    "    train_file = os.path.join(DATA_DIR, f\"combined_train_{batch_num}.jsonl\")\n",
    "    dev_file = os.path.join(DATA_DIR, f\"combined_dev_{batch_num}.jsonl\")\n",
    "    test_file = os.path.join(DATA_DIR, f\"combined_test_{batch_num}.jsonl\")\n",
    "\n",
    "    if not os.path.exists(train_file) or not os.path.exists(dev_file) or not os.path.exists(test_file):\n",
    "        print(f\"🚨 Skipping batch {batch_num}, files not found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"🚀 Processing batch {batch_num}...\")\n",
    "\n",
    "    \n",
    "    model_path = f\"/media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch{batch_num-1}\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    # Load label2id from Batch 1 to ensure consistent label space\n",
    "    with open(os.path.join(model_path, \"label2id.json\"), \"r\") as f:\n",
    "        old_label2id = json.load(f)\n",
    "    id2label = {v: k for k, v in old_label2id.items()}\n",
    "    print(f\"✅ Loaded label2id from Batch {batch_num - 1}: {old_label2id}\")\n",
    "\n",
    "    train_dataset = preprocess_dataset(load_jsonl(train_file))\n",
    "    dev_dataset = preprocess_dataset(load_jsonl(dev_file))\n",
    "    test_dataset = preprocess_dataset(load_jsonl(test_file))\n",
    "    print(f\"After splitting: Train={len(train_dataset)}, Dev={len(dev_dataset)}, Test={len(test_dataset)}\")\n",
    "\n",
    "    unique_tags = set(tag for example in train_dataset['tags'] for tag in example)\n",
    "    label2id = {tag: i for i, tag in enumerate(sorted(unique_tags))}\n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "    train_dataset = train_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer, label2id))\n",
    "    dev_dataset = dev_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer, label2id))\n",
    "    test_dataset = test_dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer, label2id))\n",
    "\n",
    "    # Load the number of labels from batch 1\n",
    "    old_num_labels = len(old_label2id)  # Should match previous training setup\n",
    "    new_num_labels = len(label2id)  # Ensure this matches the new dataset\n",
    "\n",
    "    # Load the previously trained model from batch 1\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_path, num_labels=old_num_labels\n",
    "    )\n",
    "\n",
    "    # Extract the old classifier layer\n",
    "    old_classifier = model.classifier\n",
    "\n",
    "    # Create a new classifier layer with updated label count\n",
    "    new_classifier = nn.Linear(old_classifier.in_features, new_num_labels)\n",
    "\n",
    "    # Transfer weights from the old classifier to the new one (for common labels)\n",
    "    with torch.no_grad():\n",
    "        num_common_labels = min(old_num_labels, new_num_labels)\n",
    "        new_classifier.weight[:num_common_labels, :] = old_classifier.weight[:num_common_labels, :]\n",
    "        new_classifier.bias[:num_common_labels] = old_classifier.bias[:num_common_labels]\n",
    "\n",
    "    # Assign the updated classifier to the model\n",
    "    model.classifier = new_classifier\n",
    "\n",
    "    # Save updated model before continuing training\n",
    "    model.save_pretrained(\"/media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/PubMedBERT-updated\")\n",
    "    print(f\"✅ Model updated to support new label set while keeping batch {batch_num - 1} training.\")\n",
    "\n",
    "    model_checkpoint = f\"/media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch{batch_num}\"\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(model_checkpoint, exist_ok=True)\n",
    "    print(f\"Directory ensured: {model_checkpoint}\")\n",
    "    model_path_2 = \"/media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/PubMedBERT-updated\"\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_path_2, num_labels=len(label2id))\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"PubMedBERT-finetuned-mtl\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_dir=\"./logs\",\n",
    "        learning_rate=3e-5,\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=64,\n",
    "        num_train_epochs=2,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        push_to_hub=False,\n",
    "        save_total_limit=2,\n",
    "        gradient_accumulation_steps=8,  # This simulates batch size 4 * 4 = 16\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=dev_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=lambda p: compute_metrics(p, id2label)\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    metrics = trainer.evaluate(test_dataset)\n",
    "    print(\"Test Set Performance:\")\n",
    "    print(metrics)\n",
    "    \n",
    "    model.save_pretrained(model_checkpoint)\n",
    "    tokenizer.save_pretrained(model_checkpoint)\n",
    "\n",
    "    print(f\"✅ Model trained and saved for batch {batch_num}\")\n",
    "\n",
    "    predictions, labels, _ = trainer.predict(test_dataset)\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # Save label2id to file\n",
    "    with open(f\"{model_checkpoint}/label2id.json\", \"w\") as f:\n",
    "        json.dump(label2id, f)\n",
    "    print(\"✅ Saved new_label2id mapping.\")\n",
    "\n",
    "    # Save label2id to file\n",
    "    with open(\"label2id.json\", \"w\") as f:\n",
    "        json.dump(label2id, f)\n",
    "    print(\"✅ Saved new_label2id mapping.\")\n",
    "    print(\"✅ Saved label2id mapping to model directory.\")\n",
    "\n",
    "    # results = classification_report(labels, predictions, output_dict=True)\n",
    "    # with open(f\"{model_checkpoint}_evaluation.json\", \"w\") as f:\n",
    "    #     json.dump(results, f)\n",
    "\n",
    "    # print(f\"📊 Evaluation results saved for batch {batch_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Detected batches: [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "🚀 Processing batch 21...\n",
      "✅ Loaded label2id from Batch 20: {'B-Protein': 0, 'E-Protein': 1, 'I-Protein': 2, 'O': 3, 'S-Protein': 4}\n",
      "After splitting: Train=81856, Dev=22917, Test=61643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640ae72b13d64f9fa28c8217fe2d7fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d2213f389941eba7fc5f5172266ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213280430f034532853424aaa1e28cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 20 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 03:06, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.240032</td>\n",
       "      <td>0.784922</td>\n",
       "      <td>0.792816</td>\n",
       "      <td>0.777183</td>\n",
       "      <td>0.951812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.24300816655158997, 'eval_f1': 0.7457048717345257, 'eval_precision': 0.7755476685840167, 'eval_recall': 0.7180736543909348, 'eval_accuracy': 0.9439249588332157, 'eval_runtime': 8.751, 'eval_samples_per_second': 7044.125, 'eval_steps_per_second': 110.159, 'epoch': 1.9882720875684128}\n",
      "✅ Model trained and saved for batch 21\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 22...\n",
      "✅ Loaded label2id from Batch 21: {'B-Chemical': 0, 'B-Organism': 1, 'B-Protein': 2, 'B-Regulon-operon': 3, 'I-Chemical': 4, 'I-Organism': 5, 'I-Protein': 6, 'I-Regulon-operon': 7, 'O': 8}\n",
      "After splitting: Train=81856, Dev=22917, Test=61643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43cb29897a044e31a5bf0379d8cd44e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d432ad95cda24cc599bb6b2fc0ba190e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae6523862da4dd99d3b2c5df90f9383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 21 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 03:07, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266698</td>\n",
       "      <td>0.778010</td>\n",
       "      <td>0.781171</td>\n",
       "      <td>0.774875</td>\n",
       "      <td>0.948564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.31734344363212585, 'eval_f1': 0.7585497835497835, 'eval_precision': 0.8013949233935513, 'eval_recall': 0.7200534209985617, 'eval_accuracy': 0.9319264705882353, 'eval_runtime': 8.8343, 'eval_samples_per_second': 6977.698, 'eval_steps_per_second': 109.12, 'epoch': 1.9882720875684128}\n",
      "✅ Model trained and saved for batch 22\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 23...\n",
      "✅ Loaded label2id from Batch 22: {'B-Chemical': 0, 'B-Organism': 1, 'B-Protein': 2, 'B-Regulon-operon': 3, 'E-Chemical': 4, 'E-Organism': 5, 'E-Protein': 6, 'E-Regulon-operon': 7, 'I-Chemical': 8, 'I-Organism': 9, 'I-Protein': 10, 'O': 11, 'S-Chemical': 12, 'S-Organism': 13, 'S-Protein': 14, 'S-Regulon-operon': 15}\n",
      "After splitting: Train=81856, Dev=22917, Test=61643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56caed81f554bfa987a06159a545ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b8207cb4b24739ae621524bfd99834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56efe8a383fc4876b927860ca4d12448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 22 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 03:09, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.153291</td>\n",
       "      <td>0.496046</td>\n",
       "      <td>0.708419</td>\n",
       "      <td>0.381637</td>\n",
       "      <td>0.970425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.13775230944156647, 'eval_f1': 0.5350958853099982, 'eval_precision': 0.6175333046841427, 'eval_recall': 0.4720762155059133, 'eval_accuracy': 0.9618913196894848, 'eval_runtime': 8.6592, 'eval_samples_per_second': 7118.797, 'eval_steps_per_second': 111.327, 'epoch': 1.9882720875684128}\n",
      "✅ Model trained and saved for batch 23\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 24...\n",
      "✅ Loaded label2id from Batch 23: {'B-Organism': 0, 'I-Organism': 1, 'O': 2}\n",
      "After splitting: Train=81856, Dev=22917, Test=61643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027775c54fa848b7982ce4e674395463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773934337d234a7593d476b3d9c99bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3d2b994b264aecbc91884bc59bcde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 23 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 03:06, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.195784</td>\n",
       "      <td>0.477652</td>\n",
       "      <td>0.654479</td>\n",
       "      <td>0.376050</td>\n",
       "      <td>0.967546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.1808229684829712, 'eval_f1': 0.6801535735380979, 'eval_precision': 0.7985436893203883, 'eval_recall': 0.592335390946502, 'eval_accuracy': 0.9577158315690426, 'eval_runtime': 8.6414, 'eval_samples_per_second': 7133.473, 'eval_steps_per_second': 111.556, 'epoch': 1.9882720875684128}\n",
      "✅ Model trained and saved for batch 24\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 25...\n",
      "✅ Loaded label2id from Batch 24: {'B-Organism': 0, 'E-Organism': 1, 'I-Organism': 2, 'O': 3, 'S-Organism': 4}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c95d2e2d0fd4a73b6b4e5432b7e0296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627cf27dfa5242878b87a81dbb326779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ad780bd14645619164dbca110db9c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 24 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:05, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.013473</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.996065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.011795414611697197, 'eval_f1': 0.6814159292035398, 'eval_precision': 0.7897435897435897, 'eval_recall': 0.5992217898832685, 'eval_accuracy': 0.9971174287464418, 'eval_runtime': 7.2695, 'eval_samples_per_second': 7259.235, 'eval_steps_per_second': 113.488, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 25\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 26...\n",
      "✅ Loaded label2id from Batch 25: {'B-Cellular_component': 0, 'I-Cellular_component': 1, 'O': 2}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb1db6632514ad89eda39d3012b9e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a81bbe471cba4b2f90e5c1ed5785c32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d07a5f96b374c5eb035fe65651ce759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 25 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:11, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.015420</td>\n",
       "      <td>0.668966</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.995757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.012548900209367275, 'eval_f1': 0.7173489278752436, 'eval_precision': 0.736, 'eval_recall': 0.6996197718631179, 'eval_accuracy': 0.9970093323244333, 'eval_runtime': 7.2241, 'eval_samples_per_second': 7304.867, 'eval_steps_per_second': 114.201, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 26\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 27...\n",
      "✅ Loaded label2id from Batch 26: {'B-Cellular_component': 0, 'E-Cellular_component': 1, 'I-Cellular_component': 2, 'O': 3, 'S-Cellular_component': 4}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0802d6bdcfa34ce89617f18e0bcf003d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923bbacb4b614893ab3931e64948db4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ecac9c0fcda4c68abc6e822ea71fc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 26 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:09, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.098214</td>\n",
       "      <td>0.651529</td>\n",
       "      <td>0.721026</td>\n",
       "      <td>0.594252</td>\n",
       "      <td>0.967629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.0937170535326004, 'eval_f1': 0.6692493946731236, 'eval_precision': 0.7430107526881721, 'eval_recall': 0.6088105726872247, 'eval_accuracy': 0.9687601340395633, 'eval_runtime': 7.0283, 'eval_samples_per_second': 7508.371, 'eval_steps_per_second': 117.383, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 27\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 28...\n",
      "✅ Loaded label2id from Batch 27: {'B-Cell': 0, 'I-Cell': 1, 'O': 2}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0d8619134c41db88fd22e4b6d315d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7488c5bbd6044213acbd62ed5ede5741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1e30cda70741fb8027fc6b118f8eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 27 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:02, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.116769</td>\n",
       "      <td>0.653654</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>0.607083</td>\n",
       "      <td>0.966671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.111765556037426, 'eval_f1': 0.6862838158519222, 'eval_precision': 0.7461300309597523, 'eval_recall': 0.6353251318101933, 'eval_accuracy': 0.9676251216084748, 'eval_runtime': 7.2313, 'eval_samples_per_second': 7297.58, 'eval_steps_per_second': 114.087, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 28\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 29...\n",
      "✅ Loaded label2id from Batch 28: {'B-Cell': 0, 'E-Cell': 1, 'I-Cell': 2, 'O': 3, 'S-Cell': 4}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d208ae15d303411cbbafc9acdcd99a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e99a0c0d5f419ba87d41df85ee093a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b1b581778a48b4af3085f0f1c712ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 28 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:15, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.083072</td>\n",
       "      <td>0.673493</td>\n",
       "      <td>0.783069</td>\n",
       "      <td>0.590818</td>\n",
       "      <td>0.978237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.08391667157411575, 'eval_f1': 0.6143067846607669, 'eval_precision': 0.7572727272727273, 'eval_recall': 0.5167493796526055, 'eval_accuracy': 0.9795697762404064, 'eval_runtime': 6.9364, 'eval_samples_per_second': 7607.867, 'eval_steps_per_second': 118.938, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 29\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 30...\n",
      "✅ Loaded label2id from Batch 29: {'B-Simple_chemical': 0, 'I-Simple_chemical': 1, 'O': 2}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8f5a44820648728c5d13c4047578a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e351679d33e445678c68509b800c6ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c59814245c0466f996242333752504b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 29 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:19, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.100028</td>\n",
       "      <td>0.703142</td>\n",
       "      <td>0.816352</td>\n",
       "      <td>0.617507</td>\n",
       "      <td>0.978682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.10680578649044037, 'eval_f1': 0.6139173436948075, 'eval_precision': 0.7510803802938635, 'eval_recall': 0.519115890083632, 'eval_accuracy': 0.9778402334882715, 'eval_runtime': 6.991, 'eval_samples_per_second': 7548.426, 'eval_steps_per_second': 118.009, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 30\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 31...\n",
      "✅ Loaded label2id from Batch 30: {'B-Simple_chemical': 0, 'E-Simple_chemical': 1, 'I-Simple_chemical': 2, 'O': 3, 'S-Simple_chemical': 4}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c6b239ed054d20b6f44d7902e7bb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250b771a7b7b4bcea89aaedb756e563e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cab87aa1e164638bb74fa4d0fa0f12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 30 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:14, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.191038</td>\n",
       "      <td>0.705824</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.622216</td>\n",
       "      <td>0.931905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.15393517911434174, 'eval_f1': 0.7381409377570607, 'eval_precision': 0.7783346183500386, 'eval_recall': 0.7018946636537459, 'eval_accuracy': 0.9420783338738155, 'eval_runtime': 7.1289, 'eval_samples_per_second': 7402.411, 'eval_steps_per_second': 115.726, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 31\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 32...\n",
      "✅ Loaded label2id from Batch 31: {'B-Gene_or_gene_product': 0, 'I-Gene_or_gene_product': 1, 'O': 2}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31cf1704a2ae4fb2a38d729b8cd0198e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3011e48a3b074d54bcd212a069a1ad63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1655ffdcdd1541bd9b0a0f4321eb9873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 31 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:08, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.255951</td>\n",
       "      <td>0.710290</td>\n",
       "      <td>0.831801</td>\n",
       "      <td>0.619754</td>\n",
       "      <td>0.919826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.2079063057899475, 'eval_f1': 0.7365728900255755, 'eval_precision': 0.7577572128470332, 'eval_recall': 0.7165408373369938, 'eval_accuracy': 0.931214643461968, 'eval_runtime': 7.1065, 'eval_samples_per_second': 7425.762, 'eval_steps_per_second': 116.091, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 32\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 33...\n",
      "✅ Loaded label2id from Batch 32: {'B-Gene_or_gene_product': 0, 'E-Gene_or_gene_product': 1, 'I-Gene_or_gene_product': 2, 'O': 3, 'S-Gene_or_gene_product': 4}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f99c7f7fa541a0b5daa02481cb513b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7920f042ebce4730b3c3abec01d2fa4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1df29c02c1a46f2856f14917368d6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 32 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:09, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.518682</td>\n",
       "      <td>0.676276</td>\n",
       "      <td>0.675700</td>\n",
       "      <td>0.676852</td>\n",
       "      <td>0.851663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.5061236619949341, 'eval_f1': 0.6654605977277662, 'eval_precision': 0.662536023054755, 'eval_recall': 0.6684111062654455, 'eval_accuracy': 0.8596367960220517, 'eval_runtime': 7.3749, 'eval_samples_per_second': 7155.44, 'eval_steps_per_second': 111.865, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 33\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 34...\n",
      "✅ Loaded label2id from Batch 33: {'B-Amino_acid': 0, 'B-Anatomical_system': 1, 'B-Cancer': 2, 'B-Cell': 3, 'B-Cellular_component': 4, 'B-Developing_anatomical_structure': 5, 'B-Gene_or_gene_product': 6, 'B-Immaterial_anatomical_entity': 7, 'B-Multi-tissue_structure': 8, 'B-Organ': 9, 'B-Organism': 10, 'B-Organism_subdivision': 11, 'B-Organism_substance': 12, 'B-Pathological_formation': 13, 'B-Simple_chemical': 14, 'B-Tissue': 15, 'I-Amino_acid': 16, 'I-Anatomical_system': 17, 'I-Cancer': 18, 'I-Cell': 19, 'I-Cellular_component': 20, 'I-Developing_anatomical_structure': 21, 'I-Gene_or_gene_product': 22, 'I-Immaterial_anatomical_entity': 23, 'I-Multi-tissue_structure': 24, 'I-Organ': 25, 'I-Organism': 26, 'I-Organism_subdivision': 27, 'I-Organism_substance': 28, 'I-Pathological_formation': 29, 'I-Simple_chemical': 30, 'I-Tissue': 31, 'O': 32}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece97e2ab449437e87370e39fd8e99f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e80521ef944e1699a2ddbcbcb3c89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8951cddb184712a2591c44a80ee8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 33 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:11, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.637491</td>\n",
       "      <td>0.685915</td>\n",
       "      <td>0.690947</td>\n",
       "      <td>0.680955</td>\n",
       "      <td>0.837525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.6044006943702698, 'eval_f1': 0.6725081363327491, 'eval_precision': 0.6709484050524513, 'eval_recall': 0.6740751362202466, 'eval_accuracy': 0.8475397726249032, 'eval_runtime': 7.7054, 'eval_samples_per_second': 6848.569, 'eval_steps_per_second': 107.068, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 34\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 35...\n",
      "✅ Loaded label2id from Batch 34: {'B-Amino_acid': 0, 'B-Anatomical_system': 1, 'B-Cancer': 2, 'B-Cell': 3, 'B-Cellular_component': 4, 'B-Developing_anatomical_structure': 5, 'B-Gene_or_gene_product': 6, 'B-Immaterial_anatomical_entity': 7, 'B-Multi-tissue_structure': 8, 'B-Organ': 9, 'B-Organism': 10, 'B-Organism_subdivision': 11, 'B-Organism_substance': 12, 'B-Pathological_formation': 13, 'B-Simple_chemical': 14, 'B-Tissue': 15, 'E-Amino_acid': 16, 'E-Anatomical_system': 17, 'E-Cancer': 18, 'E-Cell': 19, 'E-Cellular_component': 20, 'E-Developing_anatomical_structure': 21, 'E-Gene_or_gene_product': 22, 'E-Immaterial_anatomical_entity': 23, 'E-Multi-tissue_structure': 24, 'E-Organ': 25, 'E-Organism': 26, 'E-Organism_subdivision': 27, 'E-Organism_substance': 28, 'E-Pathological_formation': 29, 'E-Simple_chemical': 30, 'E-Tissue': 31, 'I-Amino_acid': 32, 'I-Anatomical_system': 33, 'I-Cancer': 34, 'I-Cell': 35, 'I-Cellular_component': 36, 'I-Gene_or_gene_product': 37, 'I-Immaterial_anatomical_entity': 38, 'I-Multi-tissue_structure': 39, 'I-Organism': 40, 'I-Organism_substance': 41, 'I-Pathological_formation': 42, 'I-Simple_chemical': 43, 'I-Tissue': 44, 'O': 45, 'S-Amino_acid': 46, 'S-Anatomical_system': 47, 'S-Cancer': 48, 'S-Cell': 49, 'S-Cellular_component': 50, 'S-Developing_anatomical_structure': 51, 'S-Gene_or_gene_product': 52, 'S-Immaterial_anatomical_entity': 53, 'S-Multi-tissue_structure': 54, 'S-Organ': 55, 'S-Organism': 56, 'S-Organism_subdivision': 57, 'S-Organism_substance': 58, 'S-Pathological_formation': 59, 'S-Simple_chemical': 60, 'S-Tissue': 61}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db0b4a8a26e41d781269573a1868f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125b2f75d8c144e483d3a5d638113c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a9e30731244b539d0802514c1e491d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 34 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:12, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.028438</td>\n",
       "      <td>0.789598</td>\n",
       "      <td>0.774942</td>\n",
       "      <td>0.804819</td>\n",
       "      <td>0.992677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.027232171967625618, 'eval_f1': 0.79879427279578, 'eval_precision': 0.8166409861325116, 'eval_recall': 0.7817109144542773, 'eval_accuracy': 0.9944690664072352, 'eval_runtime': 7.0447, 'eval_samples_per_second': 7490.894, 'eval_steps_per_second': 117.11, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 35\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 36...\n",
      "✅ Loaded label2id from Batch 35: {'B-Organism': 0, 'I-Organism': 1, 'O': 2}\n",
      "After splitting: Train=83467, Dev=27599, Test=52771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee420deb83af4138ac8b5d3c56c2a571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1971e1d34b4f4aab7ab9187bba0eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203cd0b90d944e829543dde18abbfadc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 35 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/326 03:21, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.034432</td>\n",
       "      <td>0.806936</td>\n",
       "      <td>0.793182</td>\n",
       "      <td>0.821176</td>\n",
       "      <td>0.992711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.03220110386610031, 'eval_f1': 0.8032424465733234, 'eval_precision': 0.8220211161387632, 'eval_recall': 0.7853025936599424, 'eval_accuracy': 0.9937844557345152, 'eval_runtime': 7.1811, 'eval_samples_per_second': 7348.636, 'eval_steps_per_second': 114.886, 'epoch': 1.993103448275862}\n",
      "✅ Model trained and saved for batch 36\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 37...\n",
      "✅ Loaded label2id from Batch 36: {'B-Organism': 0, 'E-Organism': 1, 'I-Organism': 2, 'O': 3, 'S-Organism': 4}\n",
      "After splitting: Train=75068, Dev=81071, Test=104643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6bb18be0584775a37f37c881114316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75068 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7061721c9d6e40a399f667b15ad57534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81071 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7834484e85914544851749214c7e2474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/104643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 36 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [292/292 03:24, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.199508</td>\n",
       "      <td>0.681725</td>\n",
       "      <td>0.778543</td>\n",
       "      <td>0.606323</td>\n",
       "      <td>0.941632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.205671</td>\n",
       "      <td>0.678410</td>\n",
       "      <td>0.784014</td>\n",
       "      <td>0.597877</td>\n",
       "      <td>0.941202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.190134197473526, 'eval_f1': 0.6503453310124094, 'eval_precision': 0.7675281643472498, 'eval_recall': 0.5642049883086516, 'eval_accuracy': 0.9430461142752159, 'eval_runtime': 15.7248, 'eval_samples_per_second': 6654.661, 'eval_steps_per_second': 104.04, 'epoch': 1.9957374254049447}\n",
      "✅ Model trained and saved for batch 37\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 38...\n",
      "✅ Loaded label2id from Batch 37: {'B-Protein': 0, 'I-Protein': 1, 'O': 2}\n",
      "After splitting: Train=75068, Dev=81071, Test=104643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d4713d48144ad6a39d6e83e30a6f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75068 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383966e0d5784a07aa44d7108eddd65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81071 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57c20698d2c404b9ad33c47b4addda6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/104643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 37 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='292' max='292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [292/292 03:16, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.254859</td>\n",
       "      <td>0.655415</td>\n",
       "      <td>0.770374</td>\n",
       "      <td>0.570311</td>\n",
       "      <td>0.935779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.236614</td>\n",
       "      <td>0.680435</td>\n",
       "      <td>0.773811</td>\n",
       "      <td>0.607167</td>\n",
       "      <td>0.937813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.2262895554304123, 'eval_f1': 0.6402175119298635, 'eval_precision': 0.7525436994521263, 'eval_recall': 0.5570683661645423, 'eval_accuracy': 0.9398178525498019, 'eval_runtime': 15.9052, 'eval_samples_per_second': 6579.163, 'eval_steps_per_second': 102.859, 'epoch': 1.9957374254049447}\n",
      "✅ Model trained and saved for batch 38\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 39...\n",
      "✅ Loaded label2id from Batch 38: {'B-Protein': 0, 'E-Protein': 1, 'I-Protein': 2, 'O': 3, 'S-Protein': 4}\n",
      "After splitting: Train=69244, Dev=23646, Test=46196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a451aea1764ba1b69712a5fc24ef31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/69244 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72833e96ef84524badd75c4d888e7fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23646 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252d0c51f0a244099744c6a25dd8dc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46196 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 38 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 02:57, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.025405</td>\n",
       "      <td>0.792920</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.785965</td>\n",
       "      <td>0.994954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.016089800745248795, 'eval_f1': 0.7991452991452991, 'eval_precision': 0.7840670859538784, 'eval_recall': 0.8148148148148148, 'eval_accuracy': 0.9956865848832608, 'eval_runtime': 6.5221, 'eval_samples_per_second': 7082.991, 'eval_steps_per_second': 110.7, 'epoch': 1.990757855822551}\n",
      "✅ Model trained and saved for batch 39\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🚀 Processing batch 40...\n",
      "✅ Loaded label2id from Batch 39: {'B-Cellular_component': 0, 'I-Cellular_component': 1, 'O': 2}\n",
      "After splitting: Train=69244, Dev=23646, Test=46196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b93a227e8d44adeac22ee13cb763b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/69244 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c1addb2c21413db4330849b48b76c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23646 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "982267c47c3349678f84536315dd63b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46196 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model updated to support new label set while keeping batch 39 training.\n",
      "Directory ensured: /media/smartdragon/Windows-SSD/Users/sriva/Documents/NLP/PubMedBERT/pubmedbert-finetuned-batch40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/smartdragon/Storage/anaconda3/envs/nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_55839/2564669346.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 03:01, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.030218</td>\n",
       "      <td>0.787346</td>\n",
       "      <td>0.797153</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.993944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "{'eval_loss': 0.019268926233053207, 'eval_f1': 0.8144220572640509, 'eval_precision': 0.8067226890756303, 'eval_recall': 0.8222698072805139, 'eval_accuracy': 0.9953502176493866, 'eval_runtime': 6.4472, 'eval_samples_per_second': 7165.327, 'eval_steps_per_second': 111.987, 'epoch': 1.990757855822551}\n",
      "✅ Model trained and saved for batch 40\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved new_label2id mapping.\n",
      "✅ Saved label2id mapping to model directory.\n",
      "🎉 All detected batches processed successfully!\n"
     ]
    }
   ],
   "source": [
    "batch_numbers = detect_batches()\n",
    "print(f\"📝 Detected batches: {batch_numbers}\")\n",
    "\n",
    "for batch_num in batch_numbers:\n",
    "    train_and_evaluate(batch_num)\n",
    "\n",
    "print(\"🎉 All detected batches processed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
